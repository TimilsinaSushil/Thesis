{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TimilsinaSushil/Thesis/blob/main/Location_Hyperparameter_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install inltk\n",
        "!pip install bayesian-optimization\n",
        "\n"
      ],
      "metadata": {
        "id": "wqJkcMJK2NjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICl3v-lCcTVE"
      },
      "outputs": [],
      "source": [
        "from inltk.inltk import setup\n",
        "from inltk.inltk import tokenize\n",
        "from inltk.inltk import get_embedding_vectors\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import asyncio\n",
        "asyncio.set_event_loop(asyncio.new_event_loop())\n",
        "setup('ne')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown --id 116JOC660mWu8DdiLwS8-CLDZdfDPDoeG\n",
        "df = pd.read_csv('QSN.csv')\n"
      ],
      "metadata": {
        "id": "40xhgQvnNKM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "406d0100-324d-4795-f483-e98bcab65d2f"
      },
      "execution_count": 408,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=116JOC660mWu8DdiLwS8-CLDZdfDPDoeG\n",
            "To: /content/QSN.csv\n",
            "100% 1.05M/1.05M [00:00<00:00, 110MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 423,
      "metadata": {
        "id": "Pm_8WA9veyKr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "054f1371-1570-479b-f970-a20faa01b8ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['country' 'city' 'district' 'state' 'address' 'river' 'region']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#fine type filtering\n",
        "df=df[df['CoarseType'].isin(['location'])]\n",
        "df=df[df['FineType'].isin(['country','city','district','river','region','state','address'])]\n",
        "fine_type=df['FineType'].unique()\n",
        "output_shape=len(fine_type)\n",
        "print(fine_type)\n",
        "plt.figure(figsize=(10,4))\n",
        "df.FineType.value_counts().plot(kind='bar');\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6WbV7qyfYcp"
      },
      "source": [
        "**Text Preprocessig**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 410,
      "metadata": {
        "id": "EKyDSfqefXdB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "140cc6b2-8b88-4ca1-a779-096f4307731c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 410
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 411,
      "metadata": {
        "id": "1Io9hFAeFnvW"
      },
      "outputs": [],
      "source": [
        "#removing text inside brackets and quotes\n",
        "import re\n",
        "def removeTextInsideQuotesAndBrackets(text):\n",
        "  text=re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
        "  text=re.sub(\"\\'.*?\\'\",\"\",text)\n",
        "  text=re.sub('\\\".*?\\\"',\"\",text)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 412,
      "metadata": {
        "id": "PNI1n-GzDjG-"
      },
      "outputs": [],
      "source": [
        "def removeKo(text):\n",
        "  words= text.split()\n",
        "  text=[]\n",
        "  for word in words:\n",
        "    length=len(word)\n",
        "    if(length > 2):\n",
        "      if(word[-2]=='क' and word[-1]=='ो'):\n",
        "        if(word!='कसको'):\n",
        "          word= word[:length-2]\n",
        "    text.append(word)\n",
        "  text=' '.join([word for word in text])\n",
        "  # print(text)\n",
        "  return text\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 413,
      "metadata": {
        "id": "az5FRbNyhGf0"
      },
      "outputs": [],
      "source": [
        "def preprocessing(questions):\n",
        "  questions=questions.apply(removeTextInsideQuotesAndBrackets)\n",
        "  questions = questions.apply(removeKo)\n",
        "  #tokenization\n",
        "  questions= questions.apply(lambda x: tokenize(x,'ne'))\n",
        "  #removing duplicates\n",
        "  questions= questions.apply(lambda x: list(dict.fromkeys(x)))\n",
        "  \n",
        "  questions=questions.apply(lambda x: ' '.join(x).replace('▁','').split())\n",
        "  questions=questions.apply(lambda x: ' '.join(x))\n",
        "\n",
        "  #removing numbers\n",
        "  questios=questions.apply(lambda x: ''.join(c for c in x if not c.isdigit()))\n",
        "  #removing punctuation\n",
        "  punctuation=['!','\"','#','$','&',\"'\",'(',')','*','+',',','-','.','/',':',';','<','=','>','?','@','[',\"]\",'^','_','`','{','|','}','~']\n",
        "  questions = questions.apply(lambda x: ''.join(c for c in x if c not in punctuation))\n",
        "\n",
        "  #removing stopwords\n",
        "  WHWORDS = ['कुन','कहिले','के','कति','को','कसले','कहाँ','कसलाई','कसको','कस्तो','कति','कसरी','किन','कता']\n",
        "  STOPWORDS = stopwords.words('nepali')\n",
        "  # Removig WH words from STOPWORDS\n",
        "  for word in WHWORDS:\n",
        "    if word in STOPWORDS: STOPWORDS.remove(word)\n",
        "\n",
        "  STOPWORDS=set(STOPWORDS)\n",
        "  def clean_text(text):\n",
        "      text=' '.join([word for word in text.split() if word not in STOPWORDS]) # delete stopwords from text\n",
        "      return text\n",
        "  questions = questions.apply(clean_text)\n",
        "  return questions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 414,
      "metadata": {
        "id": "pt2AN-SEoRU4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0a7d9943-e3a6-4483-8407-c90f13a65f27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Questions  \\\n",
              "1   फ्रान्स लियोन सम्पन्न महिला विश्वकप फुटबल २०१९...   \n",
              "3   फलफूल बोट रु दश नोट कार्यक्रम सुरुवात कुन जिल्...   \n",
              "13  ब्राजिल आयोजित को पा अमेरिका फुटबल २०१९ उपाधि ...   \n",
              "14  व्यावसायिक कफी खेति सर्वेक्षण २०७५ अन् सार उत्...   \n",
              "16                  प्रदेश खेलकुद विकाश परिषद गठन कुन   \n",
              "\n",
              "                          Answer CoarseType  FineType WhWord    Domain   \n",
              "1                        अमेरिका   location   country   कसले     Sports  \n",
              "3   इच्छाकामना गाउँपालिका, चितवन   location      city    कुन   Politics  \n",
              "13                       ब्राजिल   location   country   कसले     Sports  \n",
              "14                काभ्रेपलाञ्चोक   location  district    कुन  Economics  \n",
              "16                      प्रदेश ३   location     state    कुन     Sports  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c5616f8-c1c5-4f04-a439-f2167fc6e16d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "      <th>Answer</th>\n",
              "      <th>CoarseType</th>\n",
              "      <th>FineType</th>\n",
              "      <th>WhWord</th>\n",
              "      <th>Domain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>फ्रान्स लियोन सम्पन्न महिला विश्वकप फुटबल २०१९...</td>\n",
              "      <td>अमेरिका</td>\n",
              "      <td>location</td>\n",
              "      <td>country</td>\n",
              "      <td>कसले</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>फलफूल बोट रु दश नोट कार्यक्रम सुरुवात कुन जिल्...</td>\n",
              "      <td>इच्छाकामना गाउँपालिका, चितवन</td>\n",
              "      <td>location</td>\n",
              "      <td>city</td>\n",
              "      <td>कुन</td>\n",
              "      <td>Politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ब्राजिल आयोजित को पा अमेरिका फुटबल २०१९ उपाधि ...</td>\n",
              "      <td>ब्राजिल</td>\n",
              "      <td>location</td>\n",
              "      <td>country</td>\n",
              "      <td>कसले</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>व्यावसायिक कफी खेति सर्वेक्षण २०७५ अन् सार उत्...</td>\n",
              "      <td>काभ्रेपलाञ्चोक</td>\n",
              "      <td>location</td>\n",
              "      <td>district</td>\n",
              "      <td>कुन</td>\n",
              "      <td>Economics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>प्रदेश खेलकुद विकाश परिषद गठन कुन</td>\n",
              "      <td>प्रदेश ३</td>\n",
              "      <td>location</td>\n",
              "      <td>state</td>\n",
              "      <td>कुन</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c5616f8-c1c5-4f04-a439-f2167fc6e16d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c5616f8-c1c5-4f04-a439-f2167fc6e16d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c5616f8-c1c5-4f04-a439-f2167fc6e16d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 414
        }
      ],
      "source": [
        "df['Questions'] = preprocessing(df['Questions'])\n",
        "\n",
        "dataset=df\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['Questions'])\n",
        "vocab_size=len(tokenizer.word_index)\n",
        "sequences = tokenizer.texts_to_sequences(df['Questions'])\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "maxlen = max([len(i) for i in sequences])\n",
        "padded_sequences = pad_sequences(sequences, maxlen)"
      ],
      "metadata": {
        "id": "Ci8UiNrqlXV8"
      },
      "execution_count": 415,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OdUOEiOYUpe"
      },
      "source": [
        "**One hot encoding of labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 416,
      "metadata": {
        "id": "XEu4OgpGYcw3"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "le = preprocessing.LabelEncoder()\n",
        "y=df.FineType\n",
        "# print(y.unique())\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM**"
      ],
      "metadata": {
        "id": "1RnDnCFGn-uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svm(k_fold,test_size):\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.pipeline import Pipeline\n",
        "  from sklearn.feature_extraction.text import TfidfTransformer\n",
        "  from sklearn.feature_extraction.text import CountVectorizer\n",
        "  from sklearn.svm import SVC\n",
        "  from sklearn.naive_bayes import MultinomialNB\n",
        "  from sklearn.model_selection import StratifiedKFold\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  from sklearn.metrics import fbeta_score\n",
        "  from sklearn.metrics import classification_report\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  import random \n",
        "  test_size=0.30\n",
        "  k_fold = 5\n",
        "  X = dataset.Questions\n",
        "  y = dataset.FineType\n",
        "\n",
        "  # Splitting test set\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size) \n",
        "\n",
        "  metrics = []\n",
        "  skf= StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=1)\n",
        "  X=np.array(X_train)\n",
        "  y=np.array(y_train)\n",
        "\n",
        "  # Defining Model\n",
        "  model = Pipeline([('vect', CountVectorizer()),\n",
        "              ('tfidf', TfidfTransformer()),\n",
        "              ('clf', MultinomialNB()),\n",
        "              ]) \n",
        "\n",
        "    \n",
        "    #gaussian\n",
        "    #sigmoid\n",
        "  #model defination finished\n",
        "\n",
        "\n",
        "  # K fold cross validation\n",
        "  for train_index, validation_index in skf.split(X, y):\n",
        "      # print(\"TRAIN:\", train_index, \"VALIDATION:\", validation_index)\n",
        "      X_train, X_validation = X[train_index], X[validation_index]\n",
        "      y_train, y_validation = y[train_index], y[validation_index]\n",
        "  #   # train the model\n",
        "      model.fit(X_train,y_train)\n",
        "  #   # validate the model \n",
        "      y_pred_class_for_validation = model.predict(X_validation)\n",
        "      metrics.append(accuracy_score(y_validation, y_pred_class_for_validation))\n",
        "      # print(classification_report(y_test, y_pred_class,target_names=coarse_type))\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  metrics = np.array(metrics)\n",
        "  # print('Validation Accuracy for each Iteration',metrics)\n",
        "  # print('Mean accuracy for validation set: ', np.mean(metrics, axis=0))\n",
        "  # print('Std for accuracy: ', np.std(metrics, axis=0))\n",
        "  # print('---------------------------------------------------------------------------------')\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  test_accuracy = accuracy_score(y_pred, y_test)\n",
        "  # print('Test Accuracy : %s' % test_accuracy)\n",
        "  # print(classification_report(y_test, y_pred,target_names=fine_type))\n",
        "\n",
        "  # cf_matrix = confusion_matrix(y_test, y_pred, labels=fine_type)\n",
        "  # print(cf_matrix)\n",
        "\n",
        "  # import seaborn as sns\n",
        "  # plt.figure(figsize=(8,7))\n",
        "  # actual_data= ['temporal' 'location' 'numerical' 'person' 'organization' 'explanation' 'miscellaneous']\n",
        "  # predicted_data= ['temporal' 'location' 'numerical' 'person' 'organization' 'explanation' 'miscellaneous']\n",
        "  # cm = confusion_matrix(actual_data, predicted_data)\n",
        "  # ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g')\n",
        "  # ax.set_title('Confusion Matrix')\n",
        "  # ax.set_xlabel('Predicted Intent')\n",
        "  # ax.set_ylabel('Actual Intent')\n",
        "  # ax.xaxis.set_ticklabels(['TEM','LOC','NUM','PER','ORG','EXP','MISC'])\n",
        "  # ax.yaxis.set_ticklabels(['TEM','LOC','NUM','PER','ORG','EXP','MISC'])\n",
        "  # plt.show()\n",
        "  \n",
        "  return test_accuracy\n"
      ],
      "metadata": {
        "id": "AZ9a0OXZoDbf"
      },
      "execution_count": 417,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "nRmFeZfhPm_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def randomForest(k_fold,test_size,n_estimators):\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.model_selection import StratifiedKFold\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  from sklearn.metrics import fbeta_score\n",
        "  from sklearn.metrics import classification_report\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  \n",
        "  x=padded_sequences\n",
        "  test_size=0.2\n",
        "  k_fold=5\n",
        "  # max_depth=2\n",
        "  n_estimators=100\n",
        "\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y,stratify=y,test_size=test_size) \n",
        "  metrics = []\n",
        "  skf= StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "  #Create a Gaussian Classifier\n",
        "  model=RandomForestClassifier(n_estimators=n_estimators)\n",
        "\n",
        "   # K fold cross validation\n",
        "  for train_index, validation_index in skf.split(x_train, y_train):\n",
        "      # print(\"TRAIN:\", train_index, \"VALIDATION:\", validation_index)\n",
        "      X_train, X_validation = x_train[train_index], x_train[validation_index]\n",
        "      Y_train, Y_validation = y_train[train_index], y_train[validation_index]\n",
        "     \n",
        "  #   # train the model\n",
        "      model.fit(X_train,Y_train)\n",
        "  #   # validate the model \n",
        "      Y_pred_class_for_validation = model.predict(X_validation)\n",
        "      metrics.append(accuracy_score(Y_validation, Y_pred_class_for_validation))\n",
        "      # print(classification_report(y_test, y_pred_class,target_names=coarse_type))\n",
        "\n",
        "  # metrics = np.array(metrics)\n",
        "  # print('Validation Accuracy for each Iteration',metrics)\n",
        "  # print('Mean accuracy for validation set: ', np.mean(metrics, axis=0))\n",
        "  # print('Std for accuracy: ', np.std(metrics, axis=0))\n",
        "  # print('---------------------------------------------------------------------------------')\n",
        "\n",
        " \n",
        "\n",
        "  y_pred=model.predict(x_test)\n",
        "  test_accuracy=accuracy_score(y_test, y_pred)\n",
        "\n",
        "  # print(\"Test Accuracy:\",test_accuracy)\n",
        "  return test_accuracy"
      ],
      "metadata": {
        "id": "FPYZjOYlPw81"
      },
      "execution_count": 418,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DNN**"
      ],
      "metadata": {
        "id": "F1XRt4nKVrNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def dnn(k_fold,test_size,epochs,learning_rate,batch_size,vect_dim,neurons,dropout):\n",
        "  from keras.models import Sequential\n",
        "  from keras.layers import Dense, Flatten, Dropout\n",
        "  from keras.layers.embeddings import Embedding\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.model_selection import StratifiedKFold\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  from sklearn.metrics import fbeta_score\n",
        "  from sklearn.metrics import classification_report\n",
        "\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  y=df.FineType\n",
        "  # print(y.unique())\n",
        "  y = le.fit_transform(y)\n",
        "  y = to_categorical(y) \n",
        "\n",
        "  test_size=0.2\n",
        "  k_fold=5\n",
        "\n",
        "  epochs=20\n",
        "  learning_rate= 0.002\n",
        "  batch_size=40\n",
        "  vect_dim=32\n",
        "  neurons=128\n",
        "  dropout=0.2\n",
        "\n",
        "\n",
        "\n",
        "  x=padded_sequences;\n",
        "  # print(x)\n",
        "  # print(y)\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y,stratify=y,test_size=test_size) \n",
        "  acc = []\n",
        "  val = []\n",
        "  skf= StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=42)\n",
        "  # x=np.array(x_train)\n",
        "  # y=np.array(y_train)\n",
        "\n",
        "  max_len = max([len(i) for i in sequences])\n",
        "  # print(max_len)\n",
        "  # from keras.optimizers import Adam\n",
        "  model = Sequential() \n",
        "  model.add(Embedding(vocab_size + 1, vect_dim, input_length=max_len)) \n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(neurons, activation='relu'))\n",
        "  model.add(Dropout(dropout))\n",
        "  # print(output_shape)\n",
        "  model.add(Dense(output_shape, activation='softmax'))\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy']) \n",
        "  #default value of learning rate will be 0.001\n",
        "  #adam is a variant of SGD(Sochastic gradient descent). Learning rate should be between (0.0001 to 0.1).Objective: Minimize the loss between actual output and predicted output.\n",
        "  model.optimizer.lr=learning_rate\n",
        "  # model.summary()\n",
        "\n",
        "  # K fold cross validation\n",
        "  i=0\n",
        "  for train_index, validation_index in skf.split(x_train, y_train.argmax(1)):\n",
        "      i=i+1\n",
        "      # print(\"TRAIN:\", train_index, \"VALIDATION:\", validation_index)\n",
        "      x_train, x_validation = x[train_index], x[validation_index]\n",
        "      y_train, y_validation = y[train_index], y[validation_index]\n",
        "      hist = model.fit(x_train, y_train, validation_data=(x_validation,y_validation), epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "      ac = hist.history['categorical_accuracy']\n",
        "      # print('Average training accuracy :' +str(sum(ac)/len(ac)))\n",
        "      vl = hist.history['val_categorical_accuracy']\n",
        "      # print('Average validation accuracy :' + str(sum(vl)/len(vl)))\n",
        "      # ep = range(1, len(ac) + 1)\n",
        "      # plt.figure()\n",
        "      # plt.plot(ep, ac, '-', label='Training accuracy')\n",
        "      # plt.plot(ep, vl, ':', label='Validation accuracy')\n",
        "      # plt.title('Training and Validation Accuracy for set '+ str(i))\n",
        "      # plt.xlabel('Epoch')\n",
        "      # plt.ylabel('Accuracy')\n",
        "      # plt.legend(loc='lower right')\n",
        "      # plt.plot()\n",
        "      # acc.extend(ac);\n",
        "      # val.extend(vl)\n",
        "\n",
        "\n",
        "  # plt.figure()\n",
        "  # epochs = range(1, len(acc) + 1)\n",
        "  # plt.plot(epochs, acc, '-', label='Training accuracy')\n",
        "  # plt.plot(epochs, val, ':', label='Validation accuracy')\n",
        "  # plt.title('Overall Training and Validation Accuracy')\n",
        "  # plt.xlabel('Epoch')\n",
        "  # plt.ylabel('Accuracy')\n",
        "  # plt.legend(loc='lower right')\n",
        "  # plt.plot()\n",
        "\n",
        "\n",
        "  y_pred = model.predict(x_test)\n",
        "\n",
        "  test_accuracy = accuracy_score(y_pred.argmax(axis=1), y_test.argmax(axis=1))\n",
        "\n",
        "  beta_score=fbeta_score( y_test.argmax(axis=1), y_pred.argmax(axis=1), average='weighted', beta=1)\n",
        "  # print('Test Accuracy : %s' % test_accuracy)\n",
        "  # # print(y_pred.argmax(axis=1))\n",
        "  # # print(y_test.argmax(axis=1))\n",
        "  # labels=y.argmax(axis=1)\n",
        "  # labels=le.inverse_transform(labels)\n",
        "  # labels=np.unique(labels)\n",
        "  # # print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1),target_names=labels))\n",
        "\n",
        "  # mat = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1),labels=le.fit_transform(df.CoarseType.unique()))\n",
        "  # import seaborn as sns\n",
        "  # plt.figure(figsize=(8,7))\n",
        "  # sns.set()\n",
        "  # sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=True, cmap='Blues',xticklabels=df.CoarseType.unique(), yticklabels=df.CoarseType.unique())\n",
        "\n",
        "  # plt.xlabel('Predicted label')\n",
        "  # plt.ylabel('Actual label')\n",
        "\n",
        "  # return test_accuracy\n",
        "\n",
        "  return beta_score"
      ],
      "metadata": {
        "id": "BNNnXXqwGDdG"
      },
      "execution_count": 419,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM\n",
        "from bayes_opt import BayesianOptimization\n",
        "pbounds = {\n",
        "    'k_fold': (5, 10), \n",
        "    'test_size':(20,50),\n",
        "    }\n",
        "optimizer_svm = BayesianOptimization(\n",
        "    f=svm,\n",
        "    pbounds=pbounds,\n",
        "    verbose=2, \n",
        "    random_state=42,\n",
        ")\n",
        "optimizer_svm.maximize(init_points = 0, n_iter = 20)\n",
        "print(\"Best result: {}; Accuracy = {}.\".format(optimizer_svm.max[\"params\"], optimizer_svm.max[\"target\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4tg_TtPChES",
        "outputId": "c40bfb4b-b4aa-43d4-95a9-156123fe26a7"
      },
      "execution_count": 420,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   |  k_fold   | test_size |\n",
            "-------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5608  \u001b[0m | \u001b[0m 6.873   \u001b[0m | \u001b[0m 48.52   \u001b[0m |\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.5608  \u001b[0m | \u001b[0m 8.365   \u001b[0m | \u001b[0m 35.92   \u001b[0m |\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.5873  \u001b[0m | \u001b[95m 8.927   \u001b[0m | \u001b[95m 23.37   \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5714  \u001b[0m | \u001b[0m 5.507   \u001b[0m | \u001b[0m 35.65   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5079  \u001b[0m | \u001b[0m 5.028   \u001b[0m | \u001b[0m 33.91   \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.545   \u001b[0m | \u001b[0m 8.338   \u001b[0m | \u001b[0m 39.27   \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5714  \u001b[0m | \u001b[0m 8.946   \u001b[0m | \u001b[0m 23.29   \u001b[0m |\n",
            "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.6138  \u001b[0m | \u001b[95m 8.937   \u001b[0m | \u001b[95m 23.36   \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5238  \u001b[0m | \u001b[0m 8.917   \u001b[0m | \u001b[0m 23.34   \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.582   \u001b[0m | \u001b[0m 8.919   \u001b[0m | \u001b[0m 23.26   \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.5767  \u001b[0m | \u001b[0m 8.451   \u001b[0m | \u001b[0m 23.67   \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6138  \u001b[0m | \u001b[0m 8.02    \u001b[0m | \u001b[0m 24.55   \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5344  \u001b[0m | \u001b[0m 8.964   \u001b[0m | \u001b[0m 46.52   \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.582   \u001b[0m | \u001b[0m 5.488   \u001b[0m | \u001b[0m 35.62   \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.5767  \u001b[0m | \u001b[0m 5.575   \u001b[0m | \u001b[0m 25.95   \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.582   \u001b[0m | \u001b[0m 5.465   \u001b[0m | \u001b[0m 35.61   \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6138  \u001b[0m | \u001b[0m 5.498   \u001b[0m | \u001b[0m 35.64   \u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.5556  \u001b[0m | \u001b[0m 8.005   \u001b[0m | \u001b[0m 24.56   \u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6138  \u001b[0m | \u001b[0m 9.096   \u001b[0m | \u001b[0m 40.42   \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.5291  \u001b[0m | \u001b[0m 7.51    \u001b[0m | \u001b[0m 40.16   \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.5608  \u001b[0m | \u001b[0m 9.108   \u001b[0m | \u001b[0m 40.46   \u001b[0m |\n",
            "=================================================\n",
            "Best result: {'k_fold': 8.937498034538098, 'test_size': 23.3558599439102}; Accuracy = 0.6137566137566137.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest\n",
        "pbounds = {\n",
        "    'k_fold': (5, 10), \n",
        "    'test_size':(20,50),\n",
        "    # 'max_depth':(100,1000),\n",
        "    'n_estimators':(100,1000),\n",
        "    }\n",
        "optimizer_rf = BayesianOptimization(\n",
        "    f=randomForest,\n",
        "    pbounds=pbounds,\n",
        "    verbose=2, \n",
        "    random_state=42,\n",
        ")\n",
        "optimizer_rf.maximize(init_points = 0, n_iter = 20)\n",
        "print(\"Best result: {}; Accuracy = {}.\".format(optimizer_rf.max[\"params\"], optimizer_rf.max[\"target\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOOaebjjC3O8",
        "outputId": "d3d5e906-4cf8-487d-8bfd-df84e958e242"
      },
      "execution_count": 421,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   |  k_fold   | n_esti... | test_size |\n",
            "-------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6349  \u001b[0m | \u001b[0m 6.873   \u001b[0m | \u001b[0m 955.6   \u001b[0m | \u001b[0m 41.96   \u001b[0m |\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.627   \u001b[0m | \u001b[0m 9.857   \u001b[0m | \u001b[0m 669.2   \u001b[0m | \u001b[0m 49.58   \u001b[0m |\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.6984  \u001b[0m | \u001b[95m 6.657   \u001b[0m | \u001b[95m 956.1   \u001b[0m | \u001b[95m 40.5    \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5952  \u001b[0m | \u001b[0m 6.626   \u001b[0m | \u001b[0m 531.2   \u001b[0m | \u001b[0m 24.28   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5952  \u001b[0m | \u001b[0m 9.715   \u001b[0m | \u001b[0m 431.1   \u001b[0m | \u001b[0m 26.64   \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6667  \u001b[0m | \u001b[0m 5.967   \u001b[0m | \u001b[0m 956.3   \u001b[0m | \u001b[0m 40.41   \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5794  \u001b[0m | \u001b[0m 6.61    \u001b[0m | \u001b[0m 954.8   \u001b[0m | \u001b[0m 38.4    \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.619   \u001b[0m | \u001b[0m 6.971   \u001b[0m | \u001b[0m 955.7   \u001b[0m | \u001b[0m 39.98   \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6825  \u001b[0m | \u001b[0m 6.523   \u001b[0m | \u001b[0m 956.3   \u001b[0m | \u001b[0m 40.83   \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6667  \u001b[0m | \u001b[0m 5.929   \u001b[0m | \u001b[0m 957.0   \u001b[0m | \u001b[0m 39.98   \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6111  \u001b[0m | \u001b[0m 7.7     \u001b[0m | \u001b[0m 956.3   \u001b[0m | \u001b[0m 40.49   \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6508  \u001b[0m | \u001b[0m 6.541   \u001b[0m | \u001b[0m 875.0   \u001b[0m | \u001b[0m 22.82   \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.6825  \u001b[0m | \u001b[0m 6.022   \u001b[0m | \u001b[0m 957.0   \u001b[0m | \u001b[0m 40.69   \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6746  \u001b[0m | \u001b[0m 6.341   \u001b[0m | \u001b[0m 329.8   \u001b[0m | \u001b[0m 35.13   \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6508  \u001b[0m | \u001b[0m 8.062   \u001b[0m | \u001b[0m 155.4   \u001b[0m | \u001b[0m 32.75   \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6429  \u001b[0m | \u001b[0m 6.356   \u001b[0m | \u001b[0m 328.7   \u001b[0m | \u001b[0m 36.39   \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6587  \u001b[0m | \u001b[0m 9.729   \u001b[0m | \u001b[0m 506.3   \u001b[0m | \u001b[0m 47.31   \u001b[0m |\n",
            "| \u001b[95m 18      \u001b[0m | \u001b[95m 0.7063  \u001b[0m | \u001b[95m 7.983   \u001b[0m | \u001b[95m 155.5   \u001b[0m | \u001b[95m 32.92   \u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6508  \u001b[0m | \u001b[0m 6.682   \u001b[0m | \u001b[0m 152.3   \u001b[0m | \u001b[0m 46.36   \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7063  \u001b[0m | \u001b[0m 5.986   \u001b[0m | \u001b[0m 330.2   \u001b[0m | \u001b[0m 35.17   \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6746  \u001b[0m | \u001b[0m 6.646   \u001b[0m | \u001b[0m 966.8   \u001b[0m | \u001b[0m 35.16   \u001b[0m |\n",
            "=============================================================\n",
            "Best result: {'k_fold': 7.983255640497452, 'n_estimators': 155.50130834110604, 'test_size': 32.91612091956322}; Accuracy = 0.7063492063492064.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DNN\n",
        "pbounds = {\n",
        "    'k_fold': (5, 10), \n",
        "    'test_size':(20,50),\n",
        "    'epochs': (10,50), \n",
        "    'learning_rate':(0.0001,0.01),\n",
        "    'batch_size': (10, 100), \n",
        "    'vect_dim':(8,128),\n",
        "    'neurons':(8,128),\n",
        "    'dropout':(0.2,0.8)\n",
        "    }\n",
        "optimizer_dnn = BayesianOptimization(\n",
        "    f=dnn,\n",
        "    pbounds=pbounds,\n",
        "    verbose=2, \n",
        "    random_state=42,\n",
        ")\n",
        "optimizer_dnn.maximize(init_points = 0, n_iter = 20)\n",
        "print(\"Best result: {}; Accuracy = {}.\".format(optimizer_dnn.max[\"params\"], optimizer_dnn.max[\"target\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsphAgqyDDKm",
        "outputId": "25ad82d4-3968-4f4f-873f-6cc052ab7ef2"
      },
      "execution_count": 424,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   | batch_... |  dropout  |  epochs   |  k_fold   | learni... |  neurons  | test_size | vect_dim  |\n",
            "-------------------------------------------------------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9607  \u001b[0m | \u001b[0m 43.71   \u001b[0m | \u001b[0m 0.7704  \u001b[0m | \u001b[0m 39.28   \u001b[0m | \u001b[0m 7.993   \u001b[0m | \u001b[0m 0.001645\u001b[0m | \u001b[0m 26.72   \u001b[0m | \u001b[0m 21.74   \u001b[0m | \u001b[0m 111.9   \u001b[0m |\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.9602  \u001b[0m | \u001b[0m 44.25   \u001b[0m | \u001b[0m 0.7151  \u001b[0m | \u001b[0m 40.18   \u001b[0m | \u001b[0m 5.092   \u001b[0m | \u001b[0m 0.001748\u001b[0m | \u001b[0m 64.88   \u001b[0m | \u001b[0m 39.76   \u001b[0m | \u001b[0m 93.82   \u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.9447  \u001b[0m | \u001b[0m 43.91   \u001b[0m | \u001b[0m 0.2772  \u001b[0m | \u001b[0m 35.76   \u001b[0m | \u001b[0m 9.823   \u001b[0m | \u001b[0m 0.005932\u001b[0m | \u001b[0m 31.93   \u001b[0m | \u001b[0m 22.94   \u001b[0m | \u001b[0m 104.0   \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 22.27   \u001b[0m | \u001b[0m 0.6042  \u001b[0m | \u001b[0m 30.45   \u001b[0m | \u001b[0m 5.131   \u001b[0m | \u001b[0m 0.000649\u001b[0m | \u001b[0m 37.76   \u001b[0m | \u001b[0m 49.14   \u001b[0m | \u001b[0m 102.8   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9512  \u001b[0m | \u001b[0m 59.33   \u001b[0m | \u001b[0m 0.7474  \u001b[0m | \u001b[0m 13.38   \u001b[0m | \u001b[0m 7.246   \u001b[0m | \u001b[0m 0.002067\u001b[0m | \u001b[0m 78.88   \u001b[0m | \u001b[0m 31.66   \u001b[0m | \u001b[0m 82.75   \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.9529  \u001b[0m | \u001b[0m 33.54   \u001b[0m | \u001b[0m 0.692   \u001b[0m | \u001b[0m 49.18   \u001b[0m | \u001b[0m 5.756   \u001b[0m | \u001b[0m 0.008449\u001b[0m | \u001b[0m 97.7    \u001b[0m | \u001b[0m 39.55   \u001b[0m | \u001b[0m 116.8   \u001b[0m |\n",
            "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.9608  \u001b[0m | \u001b[95m 67.32   \u001b[0m | \u001b[95m 0.4681  \u001b[0m | \u001b[95m 36.7    \u001b[0m | \u001b[95m 8.518   \u001b[0m | \u001b[95m 0.008559\u001b[0m | \u001b[95m 84.86   \u001b[0m | \u001b[95m 42.19   \u001b[0m | \u001b[95m 65.23   \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.913   \u001b[0m | \u001b[0m 70.5    \u001b[0m | \u001b[0m 0.6654  \u001b[0m | \u001b[0m 16.5    \u001b[0m | \u001b[0m 5.646   \u001b[0m | \u001b[0m 0.003515\u001b[0m | \u001b[0m 11.42   \u001b[0m | \u001b[0m 23.57   \u001b[0m | \u001b[0m 122.0   \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.9292  \u001b[0m | \u001b[0m 78.21   \u001b[0m | \u001b[0m 0.7808  \u001b[0m | \u001b[0m 48.8    \u001b[0m | \u001b[0m 8.696   \u001b[0m | \u001b[0m 0.00806 \u001b[0m | \u001b[0m 95.7    \u001b[0m | \u001b[0m 40.3    \u001b[0m | \u001b[0m 116.6   \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9452  \u001b[0m | \u001b[0m 87.54   \u001b[0m | \u001b[0m 0.6045  \u001b[0m | \u001b[0m 13.02   \u001b[0m | \u001b[0m 7.592   \u001b[0m | \u001b[0m 0.002777\u001b[0m | \u001b[0m 89.1    \u001b[0m | \u001b[0m 34.54   \u001b[0m | \u001b[0m 82.44   \u001b[0m |\n",
            "| \u001b[95m 11      \u001b[0m | \u001b[95m 0.9677  \u001b[0m | \u001b[95m 22.16   \u001b[0m | \u001b[95m 0.2169  \u001b[0m | \u001b[95m 29.25   \u001b[0m | \u001b[95m 8.622   \u001b[0m | \u001b[95m 0.00904 \u001b[0m | \u001b[95m 26.01   \u001b[0m | \u001b[95m 44.82   \u001b[0m | \u001b[95m 87.25   \u001b[0m |\n",
            "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.9765  \u001b[0m | \u001b[95m 48.43   \u001b[0m | \u001b[95m 0.6182  \u001b[0m | \u001b[95m 37.18   \u001b[0m | \u001b[95m 8.911   \u001b[0m | \u001b[95m 0.000470\u001b[0m | \u001b[95m 28.59   \u001b[0m | \u001b[95m 23.21   \u001b[0m | \u001b[95m 114.1   \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.9684  \u001b[0m | \u001b[0m 51.1    \u001b[0m | \u001b[0m 0.4514  \u001b[0m | \u001b[0m 36.47   \u001b[0m | \u001b[0m 6.302   \u001b[0m | \u001b[0m 0.005951\u001b[0m | \u001b[0m 29.02   \u001b[0m | \u001b[0m 28.06   \u001b[0m | \u001b[0m 118.2   \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.9679  \u001b[0m | \u001b[0m 49.32   \u001b[0m | \u001b[0m 0.5378  \u001b[0m | \u001b[0m 42.52   \u001b[0m | \u001b[0m 6.175   \u001b[0m | \u001b[0m 0.003714\u001b[0m | \u001b[0m 31.83   \u001b[0m | \u001b[0m 20.11   \u001b[0m | \u001b[0m 121.8   \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9757  \u001b[0m | \u001b[0m 52.98   \u001b[0m | \u001b[0m 0.6897  \u001b[0m | \u001b[0m 43.73   \u001b[0m | \u001b[0m 6.913   \u001b[0m | \u001b[0m 0.00875 \u001b[0m | \u001b[0m 19.18   \u001b[0m | \u001b[0m 21.91   \u001b[0m | \u001b[0m 115.4   \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.9678  \u001b[0m | \u001b[0m 54.86   \u001b[0m | \u001b[0m 0.7583  \u001b[0m | \u001b[0m 38.74   \u001b[0m | \u001b[0m 7.354   \u001b[0m | \u001b[0m 0.007668\u001b[0m | \u001b[0m 18.45   \u001b[0m | \u001b[0m 20.16   \u001b[0m | \u001b[0m 122.5   \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.9598  \u001b[0m | \u001b[0m 51.01   \u001b[0m | \u001b[0m 0.2485  \u001b[0m | \u001b[0m 49.09   \u001b[0m | \u001b[0m 7.949   \u001b[0m | \u001b[0m 0.001988\u001b[0m | \u001b[0m 27.56   \u001b[0m | \u001b[0m 28.06   \u001b[0m | \u001b[0m 112.6   \u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.9525  \u001b[0m | \u001b[0m 57.94   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 38.49   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 27.11   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 113.6   \u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.9317  \u001b[0m | \u001b[0m 45.06   \u001b[0m | \u001b[0m 0.528   \u001b[0m | \u001b[0m 44.28   \u001b[0m | \u001b[0m 6.788   \u001b[0m | \u001b[0m 0.007714\u001b[0m | \u001b[0m 19.46   \u001b[0m | \u001b[0m 28.0    \u001b[0m | \u001b[0m 123.5   \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.9524  \u001b[0m | \u001b[0m 50.57   \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 38.55   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 24.3    \u001b[0m | \u001b[0m 20.67   \u001b[0m | \u001b[0m 116.8   \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.9609  \u001b[0m | \u001b[0m 56.08   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 43.2    \u001b[0m | \u001b[0m 8.275   \u001b[0m | \u001b[0m 0.007351\u001b[0m | \u001b[0m 16.76   \u001b[0m | \u001b[0m 20.7    \u001b[0m | \u001b[0m 117.8   \u001b[0m |\n",
            "=========================================================================================================================\n",
            "Best result: {'batch_size': 48.43058205877641, 'dropout': 0.6181692787965853, 'epochs': 37.18417405643302, 'k_fold': 8.911384498825285, 'learning_rate': 0.00047044583441670885, 'neurons': 28.592088734866625, 'test_size': 23.206463082396805, 'vect_dim': 114.06723772811814}; Accuracy = 0.976488122818398.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Location_Hyperparameter_Optimization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOeyafA9eo+4+jSv2Vs/+LX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}