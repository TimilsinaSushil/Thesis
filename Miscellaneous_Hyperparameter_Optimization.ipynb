{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TimilsinaSushil/Thesis/blob/main/Miscellaneous_Hyperparameter_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install inltk\n",
        "!pip install bayesian-optimization\n",
        "\n"
      ],
      "metadata": {
        "id": "wqJkcMJK2NjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICl3v-lCcTVE"
      },
      "outputs": [],
      "source": [
        "from inltk.inltk import setup\n",
        "from inltk.inltk import tokenize\n",
        "from inltk.inltk import get_embedding_vectors\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import asyncio\n",
        "asyncio.set_event_loop(asyncio.new_event_loop())\n",
        "setup('ne')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown --id 116JOC660mWu8DdiLwS8-CLDZdfDPDoeG\n",
        "df = pd.read_csv('QSN.csv')\n"
      ],
      "metadata": {
        "id": "40xhgQvnNKM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3cd85b1-2845-4421-c1fd-9a5ccd0d588f"
      },
      "execution_count": 474,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=116JOC660mWu8DdiLwS8-CLDZdfDPDoeG\n",
            "To: /content/QSN.csv\n",
            "100% 1.05M/1.05M [00:00<00:00, 101MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 475,
      "metadata": {
        "id": "Pm_8WA9veyKr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "04c44b92-863e-46aa-b948-7ccd1a841efa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['material' 'animal' 'book' 'religion' 'disease' 'color' 'language' 'device' 'sport' 'planet']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#fine type filtering\n",
        "df=df[df['CoarseType'].isin(['miscellaneous'])]\n",
        "df=df[df['FineType'].isin(['material','animal','device','sport','book','planet','color','religion','disease','language'])]\n",
        "fine_type=df['FineType'].unique()\n",
        "output_shape=len(fine_type)\n",
        "print(fine_type)\n",
        "plt.figure(figsize=(10,4))\n",
        "df.FineType.value_counts().plot(kind='bar');\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6WbV7qyfYcp"
      },
      "source": [
        "**Text Preprocessig**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 476,
      "metadata": {
        "id": "EKyDSfqefXdB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ccebc27-ee10-4f34-b05e-3693f3ac6092"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 476
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 477,
      "metadata": {
        "id": "1Io9hFAeFnvW"
      },
      "outputs": [],
      "source": [
        "#removing text inside brackets and quotes\n",
        "import re\n",
        "def removeTextInsideQuotesAndBrackets(text):\n",
        "  text=re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
        "  text=re.sub(\"\\'.*?\\'\",\"\",text)\n",
        "  text=re.sub('\\\".*?\\\"',\"\",text)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 478,
      "metadata": {
        "id": "PNI1n-GzDjG-"
      },
      "outputs": [],
      "source": [
        "def removeKo(text):\n",
        "  words= text.split()\n",
        "  text=[]\n",
        "  for word in words:\n",
        "    length=len(word)\n",
        "    if(length > 2):\n",
        "      if(word[-2]=='क' and word[-1]=='ो'):\n",
        "        if(word!='कसको'):\n",
        "          word= word[:length-2]\n",
        "    text.append(word)\n",
        "  text=' '.join([word for word in text])\n",
        "  # print(text)\n",
        "  return text\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 479,
      "metadata": {
        "id": "az5FRbNyhGf0"
      },
      "outputs": [],
      "source": [
        "def preprocessing(questions):\n",
        "  questions=questions.apply(removeTextInsideQuotesAndBrackets)\n",
        "  questions = questions.apply(removeKo)\n",
        "  #tokenization\n",
        "  questions= questions.apply(lambda x: tokenize(x,'ne'))\n",
        "  #removing duplicates\n",
        "  questions= questions.apply(lambda x: list(dict.fromkeys(x)))\n",
        "  \n",
        "  questions=questions.apply(lambda x: ' '.join(x).replace('▁','').split())\n",
        "  questions=questions.apply(lambda x: ' '.join(x))\n",
        "\n",
        "  #removing numbers\n",
        "  questios=questions.apply(lambda x: ''.join(c for c in x if not c.isdigit()))\n",
        "  #removing punctuation\n",
        "  punctuation=['!','\"','#','$','&',\"'\",'(',')','*','+',',','-','.','/',':',';','<','=','>','?','@','[',\"]\",'^','_','`','{','|','}','~']\n",
        "  questions = questions.apply(lambda x: ''.join(c for c in x if c not in punctuation))\n",
        "\n",
        "  #removing stopwords\n",
        "  WHWORDS = ['कुन','कहिले','के','कति','को','कसले','कहाँ','कसलाई','कसको','कस्तो','कति','कसरी','किन','कता']\n",
        "  STOPWORDS = stopwords.words('nepali')\n",
        "  # Removig WH words from STOPWORDS\n",
        "  for word in WHWORDS:\n",
        "    if word in STOPWORDS: STOPWORDS.remove(word)\n",
        "\n",
        "  STOPWORDS=set(STOPWORDS)\n",
        "  def clean_text(text):\n",
        "      text=' '.join([word for word in text.split() if word not in STOPWORDS]) # delete stopwords from text\n",
        "      return text\n",
        "  questions = questions.apply(clean_text)\n",
        "  return questions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 480,
      "metadata": {
        "id": "pt2AN-SEoRU4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "094c3c51-71fb-47f6-9644-3a389ce764c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  Questions  Answer     CoarseType  FineType  \\\n",
              "183           सेतो सुन भन्नाले के बुझ ी न्छ    कपास  miscellaneous  material   \n",
              "188         सबैभन्दा लामो गर्व धारण जीव कुन  हात्ती  miscellaneous    animal   \n",
              "242              सबैभन्दा ठूलो स्थल जिव कुन  हात्ती  miscellaneous    animal   \n",
              "243        सबभन्द ा पुरानो धातु कुन मानिन्छ    तामा  miscellaneous  material   \n",
              "244  बिश्व सबैभन्दा बढी बाँच्न े प्राणी कुन   कछुवा  miscellaneous    animal   \n",
              "\n",
              "    WhWord        Domain   \n",
              "183     के  Miscellaneous  \n",
              "188    कुन  Miscellaneous  \n",
              "242    कुन    Environment  \n",
              "243     के  Miscellaneous  \n",
              "244    कुन    Environment  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8f66bbb-9f2d-4f7c-99da-3d0f2d652fb4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "      <th>Answer</th>\n",
              "      <th>CoarseType</th>\n",
              "      <th>FineType</th>\n",
              "      <th>WhWord</th>\n",
              "      <th>Domain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>सेतो सुन भन्नाले के बुझ ी न्छ</td>\n",
              "      <td>कपास</td>\n",
              "      <td>miscellaneous</td>\n",
              "      <td>material</td>\n",
              "      <td>के</td>\n",
              "      <td>Miscellaneous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>सबैभन्दा लामो गर्व धारण जीव कुन</td>\n",
              "      <td>हात्ती</td>\n",
              "      <td>miscellaneous</td>\n",
              "      <td>animal</td>\n",
              "      <td>कुन</td>\n",
              "      <td>Miscellaneous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>सबैभन्दा ठूलो स्थल जिव कुन</td>\n",
              "      <td>हात्ती</td>\n",
              "      <td>miscellaneous</td>\n",
              "      <td>animal</td>\n",
              "      <td>कुन</td>\n",
              "      <td>Environment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>सबभन्द ा पुरानो धातु कुन मानिन्छ</td>\n",
              "      <td>तामा</td>\n",
              "      <td>miscellaneous</td>\n",
              "      <td>material</td>\n",
              "      <td>के</td>\n",
              "      <td>Miscellaneous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>बिश्व सबैभन्दा बढी बाँच्न े प्राणी कुन</td>\n",
              "      <td>कछुवा</td>\n",
              "      <td>miscellaneous</td>\n",
              "      <td>animal</td>\n",
              "      <td>कुन</td>\n",
              "      <td>Environment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8f66bbb-9f2d-4f7c-99da-3d0f2d652fb4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8f66bbb-9f2d-4f7c-99da-3d0f2d652fb4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8f66bbb-9f2d-4f7c-99da-3d0f2d652fb4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 480
        }
      ],
      "source": [
        "df['Questions'] = preprocessing(df['Questions'])\n",
        "\n",
        "dataset=df\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['Questions'])\n",
        "vocab_size=len(tokenizer.word_index)\n",
        "sequences = tokenizer.texts_to_sequences(df['Questions'])\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "maxlen = max([len(i) for i in sequences])\n",
        "padded_sequences = pad_sequences(sequences, maxlen)"
      ],
      "metadata": {
        "id": "Ci8UiNrqlXV8"
      },
      "execution_count": 481,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OdUOEiOYUpe"
      },
      "source": [
        "**One hot encoding of labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 482,
      "metadata": {
        "id": "XEu4OgpGYcw3"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "le = preprocessing.LabelEncoder()\n",
        "y=df.FineType\n",
        "# print(y.unique())\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM**"
      ],
      "metadata": {
        "id": "1RnDnCFGn-uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svm(k_fold,test_size):\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.pipeline import Pipeline\n",
        "  from sklearn.feature_extraction.text import TfidfTransformer\n",
        "  from sklearn.feature_extraction.text import CountVectorizer\n",
        "  from sklearn.svm import SVC\n",
        "  from sklearn.naive_bayes import MultinomialNB\n",
        "  from sklearn.model_selection import StratifiedKFold\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  from sklearn.metrics import fbeta_score\n",
        "  from sklearn.metrics import classification_report\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  import random \n",
        "  test_size=0.30\n",
        "  k_fold = 2\n",
        "  X = dataset.Questions\n",
        "  y = dataset.FineType\n",
        "\n",
        "  # Splitting test set\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size) \n",
        "\n",
        "  metrics = []\n",
        "  skf= StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=1)\n",
        "  X=np.array(X_train)\n",
        "  y=np.array(y_train)\n",
        "\n",
        "  # Defining Model\n",
        "  model = Pipeline([('vect', CountVectorizer()),\n",
        "              ('tfidf', TfidfTransformer()),\n",
        "              ('clf', MultinomialNB()),\n",
        "              ]) \n",
        "\n",
        "    \n",
        "    #gaussian\n",
        "    #sigmoid\n",
        "  #model defination finished\n",
        "\n",
        "\n",
        "  # K fold cross validation\n",
        "  for train_index, validation_index in skf.split(X, y):\n",
        "      # print(\"TRAIN:\", train_index, \"VALIDATION:\", validation_index)\n",
        "      X_train, X_validation = X[train_index], X[validation_index]\n",
        "      y_train, y_validation = y[train_index], y[validation_index]\n",
        "  #   # train the model\n",
        "      model.fit(X_train,y_train)\n",
        "  #   # validate the model \n",
        "      y_pred_class_for_validation = model.predict(X_validation)\n",
        "      metrics.append(accuracy_score(y_validation, y_pred_class_for_validation))\n",
        "      # print(classification_report(y_test, y_pred_class,target_names=coarse_type))\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  metrics = np.array(metrics)\n",
        "  # print('Validation Accuracy for each Iteration',metrics)\n",
        "  # print('Mean accuracy for validation set: ', np.mean(metrics, axis=0))\n",
        "  # print('Std for accuracy: ', np.std(metrics, axis=0))\n",
        "  # print('---------------------------------------------------------------------------------')\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  test_accuracy = accuracy_score(y_pred, y_test)\n",
        "  # print('Test Accuracy : %s' % test_accuracy)\n",
        "  # print(classification_report(y_test, y_pred,target_names=fine_type))\n",
        "\n",
        "  # cf_matrix = confusion_matrix(y_test, y_pred, labels=fine_type)\n",
        "  # print(cf_matrix)\n",
        "\n",
        "  # import seaborn as sns\n",
        "  # plt.figure(figsize=(8,7))\n",
        "  # actual_data= ['temporal' 'location' 'numerical' 'person' 'organization' 'explanation' 'miscellaneous']\n",
        "  # predicted_data= ['temporal' 'location' 'numerical' 'person' 'organization' 'explanation' 'miscellaneous']\n",
        "  # cm = confusion_matrix(actual_data, predicted_data)\n",
        "  # ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g')\n",
        "  # ax.set_title('Confusion Matrix')\n",
        "  # ax.set_xlabel('Predicted Intent')\n",
        "  # ax.set_ylabel('Actual Intent')\n",
        "  # ax.xaxis.set_ticklabels(['TEM','LOC','NUM','PER','ORG','EXP','MISC'])\n",
        "  # ax.yaxis.set_ticklabels(['TEM','LOC','NUM','PER','ORG','EXP','MISC'])\n",
        "  # plt.show()\n",
        "  \n",
        "  return test_accuracy\n"
      ],
      "metadata": {
        "id": "AZ9a0OXZoDbf"
      },
      "execution_count": 490,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "nRmFeZfhPm_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def randomForest(k_fold,test_size,n_estimators):\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.model_selection import StratifiedKFold\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  from sklearn.metrics import fbeta_score\n",
        "  from sklearn.metrics import classification_report\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  \n",
        "  x=padded_sequences\n",
        "  test_size=0.2\n",
        "  k_fold=5\n",
        "  # max_depth=2\n",
        "  n_estimators=100\n",
        "\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y,stratify=y,test_size=test_size) \n",
        "  metrics = []\n",
        "  skf= StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "  #Create a Gaussian Classifier\n",
        "  model=RandomForestClassifier(n_estimators=n_estimators)\n",
        "\n",
        "   # K fold cross validation\n",
        "  for train_index, validation_index in skf.split(x_train, y_train):\n",
        "      # print(\"TRAIN:\", train_index, \"VALIDATION:\", validation_index)\n",
        "      X_train, X_validation = x_train[train_index], x_train[validation_index]\n",
        "      Y_train, Y_validation = y_train[train_index], y_train[validation_index]\n",
        "     \n",
        "  #   # train the model\n",
        "      model.fit(X_train,Y_train)\n",
        "  #   # validate the model \n",
        "      Y_pred_class_for_validation = model.predict(X_validation)\n",
        "      metrics.append(accuracy_score(Y_validation, Y_pred_class_for_validation))\n",
        "      # print(classification_report(y_test, y_pred_class,target_names=coarse_type))\n",
        "\n",
        "  # metrics = np.array(metrics)\n",
        "  # print('Validation Accuracy for each Iteration',metrics)\n",
        "  # print('Mean accuracy for validation set: ', np.mean(metrics, axis=0))\n",
        "  # print('Std for accuracy: ', np.std(metrics, axis=0))\n",
        "  # print('---------------------------------------------------------------------------------')\n",
        "\n",
        " \n",
        "\n",
        "  y_pred=model.predict(x_test)\n",
        "  test_accuracy=accuracy_score(y_test, y_pred)\n",
        "\n",
        "  # print(\"Test Accuracy:\",test_accuracy)\n",
        "  return test_accuracy"
      ],
      "metadata": {
        "id": "FPYZjOYlPw81"
      },
      "execution_count": 484,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DNN**"
      ],
      "metadata": {
        "id": "F1XRt4nKVrNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def dnn(k_fold,test_size,epochs,learning_rate,batch_size,vect_dim,neurons,dropout):\n",
        "  from keras.models import Sequential\n",
        "  from keras.layers import Dense, Flatten, Dropout\n",
        "  from keras.layers.embeddings import Embedding\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.model_selection import StratifiedKFold\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  from sklearn.metrics import fbeta_score\n",
        "  from sklearn.metrics import classification_report\n",
        "\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  y=df.FineType\n",
        "  # print(y.unique())\n",
        "  y = le.fit_transform(y)\n",
        "  y = to_categorical(y) \n",
        "\n",
        "  test_size=0.2\n",
        "  k_fold=5\n",
        "\n",
        "  epochs=20\n",
        "  learning_rate= 0.002\n",
        "  batch_size=40\n",
        "  vect_dim=32\n",
        "  neurons=128\n",
        "  dropout=0.2\n",
        "\n",
        "\n",
        "\n",
        "  x=padded_sequences;\n",
        "  # print(x)\n",
        "  # print(y)\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y,stratify=y,test_size=test_size) \n",
        "  acc = []\n",
        "  val = []\n",
        "  skf= StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=42)\n",
        "  # x=np.array(x_train)\n",
        "  # y=np.array(y_train)\n",
        "\n",
        "  max_len = max([len(i) for i in sequences])\n",
        "  # print(max_len)\n",
        "  # from keras.optimizers import Adam\n",
        "  model = Sequential() \n",
        "  model.add(Embedding(vocab_size + 1, vect_dim, input_length=max_len)) \n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(neurons, activation='relu'))\n",
        "  model.add(Dropout(dropout))\n",
        "  # print(output_shape)\n",
        "  model.add(Dense(output_shape, activation='softmax'))\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy']) \n",
        "  #default value of learning rate will be 0.001\n",
        "  #adam is a variant of SGD(Sochastic gradient descent). Learning rate should be between (0.0001 to 0.1).Objective: Minimize the loss between actual output and predicted output.\n",
        "  model.optimizer.lr=learning_rate\n",
        "  # model.summary()\n",
        "\n",
        "  # K fold cross validation\n",
        "  i=0\n",
        "  for train_index, validation_index in skf.split(x_train, y_train.argmax(1)):\n",
        "      i=i+1\n",
        "      # print(\"TRAIN:\", train_index, \"VALIDATION:\", validation_index)\n",
        "      x_train, x_validation = x[train_index], x[validation_index]\n",
        "      y_train, y_validation = y[train_index], y[validation_index]\n",
        "      hist = model.fit(x_train, y_train, validation_data=(x_validation,y_validation), epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "      ac = hist.history['categorical_accuracy']\n",
        "      # print('Average training accuracy :' +str(sum(ac)/len(ac)))\n",
        "      vl = hist.history['val_categorical_accuracy']\n",
        "      # print('Average validation accuracy :' + str(sum(vl)/len(vl)))\n",
        "      # ep = range(1, len(ac) + 1)\n",
        "      # plt.figure()\n",
        "      # plt.plot(ep, ac, '-', label='Training accuracy')\n",
        "      # plt.plot(ep, vl, ':', label='Validation accuracy')\n",
        "      # plt.title('Training and Validation Accuracy for set '+ str(i))\n",
        "      # plt.xlabel('Epoch')\n",
        "      # plt.ylabel('Accuracy')\n",
        "      # plt.legend(loc='lower right')\n",
        "      # plt.plot()\n",
        "      # acc.extend(ac);\n",
        "      # val.extend(vl)\n",
        "\n",
        "\n",
        "  # plt.figure()\n",
        "  # epochs = range(1, len(acc) + 1)\n",
        "  # plt.plot(epochs, acc, '-', label='Training accuracy')\n",
        "  # plt.plot(epochs, val, ':', label='Validation accuracy')\n",
        "  # plt.title('Overall Training and Validation Accuracy')\n",
        "  # plt.xlabel('Epoch')\n",
        "  # plt.ylabel('Accuracy')\n",
        "  # plt.legend(loc='lower right')\n",
        "  # plt.plot()\n",
        "\n",
        "\n",
        "  y_pred = model.predict(x_test)\n",
        "\n",
        "  test_accuracy = accuracy_score(y_pred.argmax(axis=1), y_test.argmax(axis=1))\n",
        "\n",
        "  beta_score=fbeta_score( y_test.argmax(axis=1), y_pred.argmax(axis=1), average='weighted', beta=1)\n",
        "  # print('Test Accuracy : %s' % test_accuracy)\n",
        "  # # print(y_pred.argmax(axis=1))\n",
        "  # # print(y_test.argmax(axis=1))\n",
        "  # labels=y.argmax(axis=1)\n",
        "  # labels=le.inverse_transform(labels)\n",
        "  # labels=np.unique(labels)\n",
        "  # # print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1),target_names=labels))\n",
        "\n",
        "  # mat = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1),labels=le.fit_transform(df.CoarseType.unique()))\n",
        "  # import seaborn as sns\n",
        "  # plt.figure(figsize=(8,7))\n",
        "  # sns.set()\n",
        "  # sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=True, cmap='Blues',xticklabels=df.CoarseType.unique(), yticklabels=df.CoarseType.unique())\n",
        "\n",
        "  # plt.xlabel('Predicted label')\n",
        "  # plt.ylabel('Actual label')\n",
        "\n",
        "  # return test_accuracy\n",
        "\n",
        "  return beta_score"
      ],
      "metadata": {
        "id": "BNNnXXqwGDdG"
      },
      "execution_count": 485,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM\n",
        "from bayes_opt import BayesianOptimization\n",
        "pbounds = {\n",
        "    'k_fold': (2, 10), \n",
        "    'test_size':(20,50),\n",
        "    }\n",
        "optimizer_svm = BayesianOptimization(\n",
        "    f=svm,\n",
        "    pbounds=pbounds,\n",
        "    verbose=2, \n",
        "    random_state=42,\n",
        ")\n",
        "optimizer_svm.maximize(init_points = 0, n_iter = 20)\n",
        "print(\"Best result: {}; Accuracy = {}.\".format(optimizer_svm.max[\"params\"], optimizer_svm.max[\"target\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4tg_TtPChES",
        "outputId": "9cf58fe9-af88-48df-81e8-cfb7fe62d56f"
      },
      "execution_count": 494,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   |  k_fold   | test_size |\n",
            "-------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.3582  \u001b[0m | \u001b[0m 4.996   \u001b[0m | \u001b[0m 48.52   \u001b[0m |\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.403   \u001b[0m | \u001b[95m 7.384   \u001b[0m | \u001b[95m 35.92   \u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.3582  \u001b[0m | \u001b[0m 7.323   \u001b[0m | \u001b[0m 35.94   \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.2687  \u001b[0m | \u001b[0m 2.811   \u001b[0m | \u001b[0m 35.65   \u001b[0m |\n",
            "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.5522  \u001b[0m | \u001b[95m 7.419   \u001b[0m | \u001b[95m 35.82   \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.4179  \u001b[0m | \u001b[0m 7.48    \u001b[0m | \u001b[0m 35.8    \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.3284  \u001b[0m | \u001b[0m 2.26    \u001b[0m | \u001b[0m 26.46   \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.4776  \u001b[0m | \u001b[0m 5.534   \u001b[0m | \u001b[0m 44.73   \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.4478  \u001b[0m | \u001b[0m 5.584   \u001b[0m | \u001b[0m 44.82   \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.3582  \u001b[0m | \u001b[0m 5.532   \u001b[0m | \u001b[0m 44.76   \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.4328  \u001b[0m | \u001b[0m 7.522   \u001b[0m | \u001b[0m 23.67   \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.4627  \u001b[0m | \u001b[0m 6.832   \u001b[0m | \u001b[0m 24.55   \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5075  \u001b[0m | \u001b[0m 8.342   \u001b[0m | \u001b[0m 46.52   \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.4776  \u001b[0m | \u001b[0m 5.355   \u001b[0m | \u001b[0m 24.96   \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.4627  \u001b[0m | \u001b[0m 2.92    \u001b[0m | \u001b[0m 25.95   \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.4925  \u001b[0m | \u001b[0m 9.644   \u001b[0m | \u001b[0m 27.84   \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.3731  \u001b[0m | \u001b[0m 8.508   \u001b[0m | \u001b[0m 44.07   \u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.403   \u001b[0m | \u001b[0m 3.666   \u001b[0m | \u001b[0m 43.25   \u001b[0m |\n",
            "| \u001b[95m 19      \u001b[0m | \u001b[95m 0.6119  \u001b[0m | \u001b[95m 8.553   \u001b[0m | \u001b[95m 40.42   \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.5075  \u001b[0m | \u001b[0m 6.017   \u001b[0m | \u001b[0m 40.16   \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.3134  \u001b[0m | \u001b[0m 7.077   \u001b[0m | \u001b[0m 42.96   \u001b[0m |\n",
            "=================================================\n",
            "Best result: {'k_fold': 8.553423079163746, 'test_size': 40.4233394747266}; Accuracy = 0.6119402985074627.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest\n",
        "pbounds = {\n",
        "    'k_fold': (5, 10), \n",
        "    'test_size':(20,50),\n",
        "    # 'max_depth':(100,1000),\n",
        "    'n_estimators':(100,1000),\n",
        "    }\n",
        "optimizer_rf = BayesianOptimization(\n",
        "    f=randomForest,\n",
        "    pbounds=pbounds,\n",
        "    verbose=2, \n",
        "    random_state=42,\n",
        ")\n",
        "optimizer_rf.maximize(init_points = 0, n_iter = 20)\n",
        "print(\"Best result: {}; Accuracy = {}.\".format(optimizer_rf.max[\"params\"], optimizer_rf.max[\"target\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOOaebjjC3O8",
        "outputId": "8e107b2f-c012-40e2-fa48-b60cdcc29441"
      },
      "execution_count": 495,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   |  k_fold   | n_esti... | test_size |\n",
            "-------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.4     \u001b[0m | \u001b[0m 6.873   \u001b[0m | \u001b[0m 955.6   \u001b[0m | \u001b[0m 41.96   \u001b[0m |\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.4667  \u001b[0m | \u001b[95m 9.857   \u001b[0m | \u001b[95m 669.2   \u001b[0m | \u001b[95m 49.58   \u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.4667  \u001b[0m | \u001b[0m 8.369   \u001b[0m | \u001b[0m 669.0   \u001b[0m | \u001b[0m 49.07   \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.4444  \u001b[0m | \u001b[0m 9.813   \u001b[0m | \u001b[0m 416.6   \u001b[0m | \u001b[0m 48.72   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.4222  \u001b[0m | \u001b[0m 5.016   \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.4667  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 566.3   \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.4444  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 597.5   \u001b[0m | \u001b[0m 50.0    \u001b[0m |\n",
            "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.5333  \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 734.6   \u001b[0m | \u001b[95m 20.16   \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.3333  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 787.1   \u001b[0m | \u001b[0m 20.0    \u001b[0m |\n",
            "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.5778  \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 715.1   \u001b[0m | \u001b[95m 24.37   \u001b[0m |\n",
            "| \u001b[95m 11      \u001b[0m | \u001b[95m 0.6222  \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 719.0   \u001b[0m | \u001b[95m 50.0    \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.5333  \u001b[0m | \u001b[0m 9.757   \u001b[0m | \u001b[0m 734.1   \u001b[0m | \u001b[0m 49.62   \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.4222  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 702.4   \u001b[0m | \u001b[0m 50.0    \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 7.209   \u001b[0m | \u001b[0m 722.9   \u001b[0m | \u001b[0m 38.5    \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.4222  \u001b[0m | \u001b[0m 5.992   \u001b[0m | \u001b[0m 724.8   \u001b[0m | \u001b[0m 48.94   \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.5333  \u001b[0m | \u001b[0m 6.192   \u001b[0m | \u001b[0m 717.6   \u001b[0m | \u001b[0m 46.14   \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.3556  \u001b[0m | \u001b[0m 5.88    \u001b[0m | \u001b[0m 716.8   \u001b[0m | \u001b[0m 49.69   \u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.5111  \u001b[0m | \u001b[0m 8.403   \u001b[0m | \u001b[0m 418.5   \u001b[0m | \u001b[0m 24.32   \u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.5333  \u001b[0m | \u001b[0m 6.682   \u001b[0m | \u001b[0m 152.3   \u001b[0m | \u001b[0m 46.36   \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.5556  \u001b[0m | \u001b[0m 7.606   \u001b[0m | \u001b[0m 723.8   \u001b[0m | \u001b[0m 38.81   \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.3556  \u001b[0m | \u001b[0m 5.088   \u001b[0m | \u001b[0m 718.0   \u001b[0m | \u001b[0m 45.94   \u001b[0m |\n",
            "=============================================================\n",
            "Best result: {'k_fold': 5.0, 'n_estimators': 718.9716497109937, 'test_size': 50.0}; Accuracy = 0.6222222222222222.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DNN\n",
        "pbounds = {\n",
        "    'k_fold': (5, 10), \n",
        "    'test_size':(20,50),\n",
        "    'epochs': (10,50), \n",
        "    'learning_rate':(0.0001,0.01),\n",
        "    'batch_size': (10, 100), \n",
        "    'vect_dim':(8,128),\n",
        "    'neurons':(8,128),\n",
        "    'dropout':(0.2,0.8)\n",
        "    }\n",
        "optimizer_dnn = BayesianOptimization(\n",
        "    f=dnn,\n",
        "    pbounds=pbounds,\n",
        "    verbose=2, \n",
        "    random_state=42,\n",
        ")\n",
        "optimizer_dnn.maximize(init_points = 0, n_iter = 5)\n",
        "print(\"Best result: {}; Accuracy = {}.\".format(optimizer_dnn.max[\"params\"], optimizer_dnn.max[\"target\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsphAgqyDDKm",
        "outputId": "f030a644-1a09-4b51-b43e-28591872cc4a"
      },
      "execution_count": 497,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   | batch_... |  dropout  |  epochs   |  k_fold   | learni... |  neurons  | test_size | vect_dim  |\n",
            "-------------------------------------------------------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.858   \u001b[0m | \u001b[0m 43.71   \u001b[0m | \u001b[0m 0.7704  \u001b[0m | \u001b[0m 39.28   \u001b[0m | \u001b[0m 7.993   \u001b[0m | \u001b[0m 0.001645\u001b[0m | \u001b[0m 26.72   \u001b[0m | \u001b[0m 21.74   \u001b[0m | \u001b[0m 111.9   \u001b[0m |\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 44.25   \u001b[0m | \u001b[0m 0.7151  \u001b[0m | \u001b[0m 40.18   \u001b[0m | \u001b[0m 5.092   \u001b[0m | \u001b[0m 0.001748\u001b[0m | \u001b[0m 64.88   \u001b[0m | \u001b[0m 39.76   \u001b[0m | \u001b[0m 93.82   \u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8187  \u001b[0m | \u001b[0m 43.91   \u001b[0m | \u001b[0m 0.2772  \u001b[0m | \u001b[0m 35.76   \u001b[0m | \u001b[0m 9.823   \u001b[0m | \u001b[0m 0.005932\u001b[0m | \u001b[0m 31.93   \u001b[0m | \u001b[0m 22.94   \u001b[0m | \u001b[0m 104.0   \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.794   \u001b[0m | \u001b[0m 22.27   \u001b[0m | \u001b[0m 0.6042  \u001b[0m | \u001b[0m 30.45   \u001b[0m | \u001b[0m 5.131   \u001b[0m | \u001b[0m 0.000649\u001b[0m | \u001b[0m 37.76   \u001b[0m | \u001b[0m 49.14   \u001b[0m | \u001b[0m 102.8   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8573  \u001b[0m | \u001b[0m 42.51   \u001b[0m | \u001b[0m 0.5298  \u001b[0m | \u001b[0m 36.53   \u001b[0m | \u001b[0m 5.722   \u001b[0m | \u001b[0m 0.007965\u001b[0m | \u001b[0m 17.71   \u001b[0m | \u001b[0m 23.06   \u001b[0m | \u001b[0m 108.8   \u001b[0m |\n",
            "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.9304  \u001b[0m | \u001b[95m 46.68   \u001b[0m | \u001b[95m 0.2607  \u001b[0m | \u001b[95m 33.79   \u001b[0m | \u001b[95m 6.425   \u001b[0m | \u001b[95m 0.007045\u001b[0m | \u001b[95m 13.28   \u001b[0m | \u001b[95m 23.47   \u001b[0m | \u001b[95m 114.1   \u001b[0m |\n",
            "=========================================================================================================================\n",
            "Best result: {'batch_size': 46.68318603301717, 'dropout': 0.2607473229616665, 'epochs': 33.78659207940042, 'k_fold': 6.424761015310944, 'learning_rate': 0.007044900514553738, 'neurons': 13.283884330133173, 'test_size': 23.46718976577696, 'vect_dim': 114.13858998055446}; Accuracy = 0.9304210193099083.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Miscellaneous_Hyperparameter_Optimization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO8FXZGFHg8H+0qiuAUlw/B",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}