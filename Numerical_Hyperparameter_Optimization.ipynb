{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TimilsinaSushil/Thesis/blob/main/Numerical_Hyperparameter_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install inltk\n",
        "!pip install bayesian-optimization\n",
        "\n"
      ],
      "metadata": {
        "id": "wqJkcMJK2NjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICl3v-lCcTVE"
      },
      "outputs": [],
      "source": [
        "from inltk.inltk import setup\n",
        "from inltk.inltk import tokenize\n",
        "from inltk.inltk import get_embedding_vectors\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import asyncio\n",
        "asyncio.set_event_loop(asyncio.new_event_loop())\n",
        "setup('ne')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown --id 116JOC660mWu8DdiLwS8-CLDZdfDPDoeG\n",
        "df = pd.read_csv('QSN.csv')\n"
      ],
      "metadata": {
        "id": "40xhgQvnNKM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06926589-17b7-4520-e3dd-660c56e3bab8"
      },
      "execution_count": 444,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=116JOC660mWu8DdiLwS8-CLDZdfDPDoeG\n",
            "To: /content/QSN.csv\n",
            "100% 1.05M/1.05M [00:00<00:00, 114MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 445,
      "metadata": {
        "id": "Pm_8WA9veyKr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "f546e21d-31df-436a-9334-85f4a13023d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['rank' 'money' 'percentage' 'count' 'length' 'temperture']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#fine type filtering\n",
        "df=df[df['CoarseType'].isin(['numerical'])]\n",
        "df=df[df['FineType'].isin(['count','percentage','rank','length','money','temperture'])]\n",
        "fine_type=df['FineType'].unique()\n",
        "output_shape=len(fine_type)\n",
        "print(fine_type)\n",
        "plt.figure(figsize=(10,4))\n",
        "df.FineType.value_counts().plot(kind='bar');\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6WbV7qyfYcp"
      },
      "source": [
        "**Text Preprocessig**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 446,
      "metadata": {
        "id": "EKyDSfqefXdB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f823e7a8-b1be-4232-9dd7-d547e2557599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 446
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 447,
      "metadata": {
        "id": "1Io9hFAeFnvW"
      },
      "outputs": [],
      "source": [
        "#removing text inside brackets and quotes\n",
        "import re\n",
        "def removeTextInsideQuotesAndBrackets(text):\n",
        "  text=re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
        "  text=re.sub(\"\\'.*?\\'\",\"\",text)\n",
        "  text=re.sub('\\\".*?\\\"',\"\",text)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 448,
      "metadata": {
        "id": "PNI1n-GzDjG-"
      },
      "outputs": [],
      "source": [
        "def removeKo(text):\n",
        "  words= text.split()\n",
        "  text=[]\n",
        "  for word in words:\n",
        "    length=len(word)\n",
        "    if(length > 2):\n",
        "      if(word[-2]=='क' and word[-1]=='ो'):\n",
        "        if(word!='कसको'):\n",
        "          word= word[:length-2]\n",
        "    text.append(word)\n",
        "  text=' '.join([word for word in text])\n",
        "  # print(text)\n",
        "  return text\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 449,
      "metadata": {
        "id": "az5FRbNyhGf0"
      },
      "outputs": [],
      "source": [
        "def preprocessing(questions):\n",
        "  questions=questions.apply(removeTextInsideQuotesAndBrackets)\n",
        "  questions = questions.apply(removeKo)\n",
        "  #tokenization\n",
        "  questions= questions.apply(lambda x: tokenize(x,'ne'))\n",
        "  #removing duplicates\n",
        "  questions= questions.apply(lambda x: list(dict.fromkeys(x)))\n",
        "  \n",
        "  questions=questions.apply(lambda x: ' '.join(x).replace('▁','').split())\n",
        "  questions=questions.apply(lambda x: ' '.join(x))\n",
        "\n",
        "  #removing numbers\n",
        "  questios=questions.apply(lambda x: ''.join(c for c in x if not c.isdigit()))\n",
        "  #removing punctuation\n",
        "  punctuation=['!','\"','#','$','&',\"'\",'(',')','*','+',',','-','.','/',':',';','<','=','>','?','@','[',\"]\",'^','_','`','{','|','}','~']\n",
        "  questions = questions.apply(lambda x: ''.join(c for c in x if c not in punctuation))\n",
        "\n",
        "  #removing stopwords\n",
        "  WHWORDS = ['कुन','कहिले','के','कति','को','कसले','कहाँ','कसलाई','कसको','कस्तो','कति','कसरी','किन','कता']\n",
        "  STOPWORDS = stopwords.words('nepali')\n",
        "  # Removig WH words from STOPWORDS\n",
        "  for word in WHWORDS:\n",
        "    if word in STOPWORDS: STOPWORDS.remove(word)\n",
        "\n",
        "  STOPWORDS=set(STOPWORDS)\n",
        "  def clean_text(text):\n",
        "      text=' '.join([word for word in text.split() if word not in STOPWORDS]) # delete stopwords from text\n",
        "      return text\n",
        "  questions = questions.apply(clean_text)\n",
        "  return questions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 450,
      "metadata": {
        "id": "pt2AN-SEoRU4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "66a274c9-1ed1-4856-c3a8-54df4ea152ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Questions  \\\n",
              "2   विश्व शान्ति सू चा ंक २०१९ नेपाल कति औ स्थानमा...   \n",
              "5   अर्थमन्त्री युवराज खतिवडा वि स २०७६ जेठ १५ संघ...   \n",
              "11    डु ई ङ वि जन ेश अवार्ड २०१९ नेपाल कति औ स्थानमा   \n",
              "26  केन्द्रिय तथ्यांक विभाग सार्वजनिक गरे हाल नेपा...   \n",
              "30  २०७६ बैशाख २० प्रस्तुत आर्थिक वर्ष ७७ को नीति ...   \n",
              "\n",
              "                               Answer CoarseType    FineType WhWord  \\\n",
              "2                        ७६ औ स्थानमा  numerical        rank    कति   \n",
              "5   रु १५ खर्व ३२ अर्व ९६ करोड ७१ लाख  numerical       money    कति   \n",
              "11                              ११० औ  numerical        rank    कति   \n",
              "26                              ११.४%  numerical  percentage    कति   \n",
              "30                      चार बर्षभित्र  numerical       count    कति   \n",
              "\n",
              "          Domain   \n",
              "2   Miscellaneous  \n",
              "5       Economics  \n",
              "11      Economics  \n",
              "26      Economics  \n",
              "30      Economics  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a13c4427-d5a1-409f-a1aa-e111bda0e835\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "      <th>Answer</th>\n",
              "      <th>CoarseType</th>\n",
              "      <th>FineType</th>\n",
              "      <th>WhWord</th>\n",
              "      <th>Domain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>विश्व शान्ति सू चा ंक २०१९ नेपाल कति औ स्थानमा...</td>\n",
              "      <td>७६ औ स्थानमा</td>\n",
              "      <td>numerical</td>\n",
              "      <td>rank</td>\n",
              "      <td>कति</td>\n",
              "      <td>Miscellaneous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>अर्थमन्त्री युवराज खतिवडा वि स २०७६ जेठ १५ संघ...</td>\n",
              "      <td>रु १५ खर्व ३२ अर्व ९६ करोड ७१ लाख</td>\n",
              "      <td>numerical</td>\n",
              "      <td>money</td>\n",
              "      <td>कति</td>\n",
              "      <td>Economics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>डु ई ङ वि जन ेश अवार्ड २०१९ नेपाल कति औ स्थानमा</td>\n",
              "      <td>११० औ</td>\n",
              "      <td>numerical</td>\n",
              "      <td>rank</td>\n",
              "      <td>कति</td>\n",
              "      <td>Economics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>केन्द्रिय तथ्यांक विभाग सार्वजनिक गरे हाल नेपा...</td>\n",
              "      <td>११.४%</td>\n",
              "      <td>numerical</td>\n",
              "      <td>percentage</td>\n",
              "      <td>कति</td>\n",
              "      <td>Economics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>२०७६ बैशाख २० प्रस्तुत आर्थिक वर्ष ७७ को नीति ...</td>\n",
              "      <td>चार बर्षभित्र</td>\n",
              "      <td>numerical</td>\n",
              "      <td>count</td>\n",
              "      <td>कति</td>\n",
              "      <td>Economics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a13c4427-d5a1-409f-a1aa-e111bda0e835')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a13c4427-d5a1-409f-a1aa-e111bda0e835 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a13c4427-d5a1-409f-a1aa-e111bda0e835');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 450
        }
      ],
      "source": [
        "df['Questions'] = preprocessing(df['Questions'])\n",
        "\n",
        "dataset=df\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['Questions'])\n",
        "vocab_size=len(tokenizer.word_index)\n",
        "sequences = tokenizer.texts_to_sequences(df['Questions'])\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "maxlen = max([len(i) for i in sequences])\n",
        "padded_sequences = pad_sequences(sequences, maxlen)"
      ],
      "metadata": {
        "id": "Ci8UiNrqlXV8"
      },
      "execution_count": 451,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OdUOEiOYUpe"
      },
      "source": [
        "**One hot encoding of labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 452,
      "metadata": {
        "id": "XEu4OgpGYcw3"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "le = preprocessing.LabelEncoder()\n",
        "y=df.FineType\n",
        "# print(y.unique())\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM**"
      ],
      "metadata": {
        "id": "1RnDnCFGn-uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svm(k_fold,test_size):\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.pipeline import Pipeline\n",
        "  from sklearn.feature_extraction.text import TfidfTransformer\n",
        "  from sklearn.feature_extraction.text import CountVectorizer\n",
        "  from sklearn.svm import SVC\n",
        "  from sklearn.naive_bayes import MultinomialNB\n",
        "  from sklearn.model_selection import StratifiedKFold\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  from sklearn.metrics import fbeta_score\n",
        "  from sklearn.metrics import classification_report\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  import random \n",
        "  test_size=0.30\n",
        "  k_fold = 5\n",
        "  X = dataset.Questions\n",
        "  y = dataset.FineType\n",
        "\n",
        "  # Splitting test set\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size) \n",
        "\n",
        "  metrics = []\n",
        "  skf= StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=1)\n",
        "  X=np.array(X_train)\n",
        "  y=np.array(y_train)\n",
        "\n",
        "  # Defining Model\n",
        "  model = Pipeline([('vect', CountVectorizer()),\n",
        "              ('tfidf', TfidfTransformer()),\n",
        "              ('clf', MultinomialNB()),\n",
        "              ]) \n",
        "\n",
        "    \n",
        "    #gaussian\n",
        "    #sigmoid\n",
        "  #model defination finished\n",
        "\n",
        "\n",
        "  # K fold cross validation\n",
        "  for train_index, validation_index in skf.split(X, y):\n",
        "      # print(\"TRAIN:\", train_index, \"VALIDATION:\", validation_index)\n",
        "      X_train, X_validation = X[train_index], X[validation_index]\n",
        "      y_train, y_validation = y[train_index], y[validation_index]\n",
        "  #   # train the model\n",
        "      model.fit(X_train,y_train)\n",
        "  #   # validate the model \n",
        "      y_pred_class_for_validation = model.predict(X_validation)\n",
        "      metrics.append(accuracy_score(y_validation, y_pred_class_for_validation))\n",
        "      # print(classification_report(y_test, y_pred_class,target_names=coarse_type))\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  metrics = np.array(metrics)\n",
        "  # print('Validation Accuracy for each Iteration',metrics)\n",
        "  # print('Mean accuracy for validation set: ', np.mean(metrics, axis=0))\n",
        "  # print('Std for accuracy: ', np.std(metrics, axis=0))\n",
        "  # print('---------------------------------------------------------------------------------')\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  test_accuracy = accuracy_score(y_pred, y_test)\n",
        "  # print('Test Accuracy : %s' % test_accuracy)\n",
        "  # print(classification_report(y_test, y_pred,target_names=fine_type))\n",
        "\n",
        "  # cf_matrix = confusion_matrix(y_test, y_pred, labels=fine_type)\n",
        "  # print(cf_matrix)\n",
        "\n",
        "  # import seaborn as sns\n",
        "  # plt.figure(figsize=(8,7))\n",
        "  # actual_data= ['temporal' 'location' 'numerical' 'person' 'organization' 'explanation' 'miscellaneous']\n",
        "  # predicted_data= ['temporal' 'location' 'numerical' 'person' 'organization' 'explanation' 'miscellaneous']\n",
        "  # cm = confusion_matrix(actual_data, predicted_data)\n",
        "  # ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g')\n",
        "  # ax.set_title('Confusion Matrix')\n",
        "  # ax.set_xlabel('Predicted Intent')\n",
        "  # ax.set_ylabel('Actual Intent')\n",
        "  # ax.xaxis.set_ticklabels(['TEM','LOC','NUM','PER','ORG','EXP','MISC'])\n",
        "  # ax.yaxis.set_ticklabels(['TEM','LOC','NUM','PER','ORG','EXP','MISC'])\n",
        "  # plt.show()\n",
        "  \n",
        "  return test_accuracy\n"
      ],
      "metadata": {
        "id": "AZ9a0OXZoDbf"
      },
      "execution_count": 453,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "nRmFeZfhPm_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def randomForest(k_fold,test_size,n_estimators):\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.model_selection import StratifiedKFold\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  from sklearn.metrics import fbeta_score\n",
        "  from sklearn.metrics import classification_report\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  \n",
        "  x=padded_sequences\n",
        "  test_size=0.2\n",
        "  k_fold=5\n",
        "  # max_depth=2\n",
        "  n_estimators=100\n",
        "\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y,stratify=y,test_size=test_size) \n",
        "  metrics = []\n",
        "  skf= StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "  #Create a Gaussian Classifier\n",
        "  model=RandomForestClassifier(n_estimators=n_estimators)\n",
        "\n",
        "   # K fold cross validation\n",
        "  for train_index, validation_index in skf.split(x_train, y_train):\n",
        "      # print(\"TRAIN:\", train_index, \"VALIDATION:\", validation_index)\n",
        "      X_train, X_validation = x_train[train_index], x_train[validation_index]\n",
        "      Y_train, Y_validation = y_train[train_index], y_train[validation_index]\n",
        "     \n",
        "  #   # train the model\n",
        "      model.fit(X_train,Y_train)\n",
        "  #   # validate the model \n",
        "      Y_pred_class_for_validation = model.predict(X_validation)\n",
        "      metrics.append(accuracy_score(Y_validation, Y_pred_class_for_validation))\n",
        "      # print(classification_report(y_test, y_pred_class,target_names=coarse_type))\n",
        "\n",
        "  # metrics = np.array(metrics)\n",
        "  # print('Validation Accuracy for each Iteration',metrics)\n",
        "  # print('Mean accuracy for validation set: ', np.mean(metrics, axis=0))\n",
        "  # print('Std for accuracy: ', np.std(metrics, axis=0))\n",
        "  # print('---------------------------------------------------------------------------------')\n",
        "\n",
        " \n",
        "\n",
        "  y_pred=model.predict(x_test)\n",
        "  test_accuracy=accuracy_score(y_test, y_pred)\n",
        "\n",
        "  # print(\"Test Accuracy:\",test_accuracy)\n",
        "  return test_accuracy"
      ],
      "metadata": {
        "id": "FPYZjOYlPw81"
      },
      "execution_count": 454,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DNN**"
      ],
      "metadata": {
        "id": "F1XRt4nKVrNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def dnn(k_fold,test_size,epochs,learning_rate,batch_size,vect_dim,neurons,dropout):\n",
        "  from keras.models import Sequential\n",
        "  from keras.layers import Dense, Flatten, Dropout\n",
        "  from keras.layers.embeddings import Embedding\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.model_selection import StratifiedKFold\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  from sklearn.metrics import fbeta_score\n",
        "  from sklearn.metrics import classification_report\n",
        "\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  y=df.FineType\n",
        "  # print(y.unique())\n",
        "  y = le.fit_transform(y)\n",
        "  y = to_categorical(y) \n",
        "\n",
        "  test_size=0.2\n",
        "  k_fold=5\n",
        "\n",
        "  epochs=20\n",
        "  learning_rate= 0.002\n",
        "  batch_size=40\n",
        "  vect_dim=32\n",
        "  neurons=128\n",
        "  dropout=0.2\n",
        "\n",
        "\n",
        "\n",
        "  x=padded_sequences;\n",
        "  # print(x)\n",
        "  # print(y)\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y,stratify=y,test_size=test_size) \n",
        "  acc = []\n",
        "  val = []\n",
        "  skf= StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=42)\n",
        "  # x=np.array(x_train)\n",
        "  # y=np.array(y_train)\n",
        "\n",
        "  max_len = max([len(i) for i in sequences])\n",
        "  # print(max_len)\n",
        "  # from keras.optimizers import Adam\n",
        "  model = Sequential() \n",
        "  model.add(Embedding(vocab_size + 1, vect_dim, input_length=max_len)) \n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(neurons, activation='relu'))\n",
        "  model.add(Dropout(dropout))\n",
        "  # print(output_shape)\n",
        "  model.add(Dense(output_shape, activation='softmax'))\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy']) \n",
        "  #default value of learning rate will be 0.001\n",
        "  #adam is a variant of SGD(Sochastic gradient descent). Learning rate should be between (0.0001 to 0.1).Objective: Minimize the loss between actual output and predicted output.\n",
        "  model.optimizer.lr=learning_rate\n",
        "  # model.summary()\n",
        "\n",
        "  # K fold cross validation\n",
        "  i=0\n",
        "  for train_index, validation_index in skf.split(x_train, y_train.argmax(1)):\n",
        "      i=i+1\n",
        "      # print(\"TRAIN:\", train_index, \"VALIDATION:\", validation_index)\n",
        "      x_train, x_validation = x[train_index], x[validation_index]\n",
        "      y_train, y_validation = y[train_index], y[validation_index]\n",
        "      hist = model.fit(x_train, y_train, validation_data=(x_validation,y_validation), epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "      ac = hist.history['categorical_accuracy']\n",
        "      # print('Average training accuracy :' +str(sum(ac)/len(ac)))\n",
        "      vl = hist.history['val_categorical_accuracy']\n",
        "      # print('Average validation accuracy :' + str(sum(vl)/len(vl)))\n",
        "      # ep = range(1, len(ac) + 1)\n",
        "      # plt.figure()\n",
        "      # plt.plot(ep, ac, '-', label='Training accuracy')\n",
        "      # plt.plot(ep, vl, ':', label='Validation accuracy')\n",
        "      # plt.title('Training and Validation Accuracy for set '+ str(i))\n",
        "      # plt.xlabel('Epoch')\n",
        "      # plt.ylabel('Accuracy')\n",
        "      # plt.legend(loc='lower right')\n",
        "      # plt.plot()\n",
        "      # acc.extend(ac);\n",
        "      # val.extend(vl)\n",
        "\n",
        "\n",
        "  # plt.figure()\n",
        "  # epochs = range(1, len(acc) + 1)\n",
        "  # plt.plot(epochs, acc, '-', label='Training accuracy')\n",
        "  # plt.plot(epochs, val, ':', label='Validation accuracy')\n",
        "  # plt.title('Overall Training and Validation Accuracy')\n",
        "  # plt.xlabel('Epoch')\n",
        "  # plt.ylabel('Accuracy')\n",
        "  # plt.legend(loc='lower right')\n",
        "  # plt.plot()\n",
        "\n",
        "\n",
        "  y_pred = model.predict(x_test)\n",
        "\n",
        "  test_accuracy = accuracy_score(y_pred.argmax(axis=1), y_test.argmax(axis=1))\n",
        "\n",
        "  beta_score=fbeta_score( y_test.argmax(axis=1), y_pred.argmax(axis=1), average='weighted', beta=1)\n",
        "  # print('Test Accuracy : %s' % test_accuracy)\n",
        "  # # print(y_pred.argmax(axis=1))\n",
        "  # # print(y_test.argmax(axis=1))\n",
        "  # labels=y.argmax(axis=1)\n",
        "  # labels=le.inverse_transform(labels)\n",
        "  # labels=np.unique(labels)\n",
        "  # # print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1),target_names=labels))\n",
        "\n",
        "  # mat = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1),labels=le.fit_transform(df.CoarseType.unique()))\n",
        "  # import seaborn as sns\n",
        "  # plt.figure(figsize=(8,7))\n",
        "  # sns.set()\n",
        "  # sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=True, cmap='Blues',xticklabels=df.CoarseType.unique(), yticklabels=df.CoarseType.unique())\n",
        "\n",
        "  # plt.xlabel('Predicted label')\n",
        "  # plt.ylabel('Actual label')\n",
        "\n",
        "  # return test_accuracy\n",
        "\n",
        "  return beta_score"
      ],
      "metadata": {
        "id": "BNNnXXqwGDdG"
      },
      "execution_count": 455,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM\n",
        "from bayes_opt import BayesianOptimization\n",
        "pbounds = {\n",
        "    'k_fold': (5, 10), \n",
        "    'test_size':(20,50),\n",
        "    }\n",
        "optimizer_svm = BayesianOptimization(\n",
        "    f=svm,\n",
        "    pbounds=pbounds,\n",
        "    verbose=2, \n",
        "    random_state=42,\n",
        ")\n",
        "optimizer_svm.maximize(init_points = 0, n_iter = 20)\n",
        "print(\"Best result: {}; Accuracy = {}.\".format(optimizer_svm.max[\"params\"], optimizer_svm.max[\"target\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4tg_TtPChES",
        "outputId": "b7031f3c-d0eb-4a61-d36e-1841adf3d52d"
      },
      "execution_count": 456,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   |  k_fold   | test_size |\n",
            "-------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6835  \u001b[0m | \u001b[0m 6.873   \u001b[0m | \u001b[0m 48.52   \u001b[0m |\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.6519  \u001b[0m | \u001b[0m 8.365   \u001b[0m | \u001b[0m 35.92   \u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.6456  \u001b[0m | \u001b[0m 6.962   \u001b[0m | \u001b[0m 48.55   \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6519  \u001b[0m | \u001b[0m 5.507   \u001b[0m | \u001b[0m 35.65   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6709  \u001b[0m | \u001b[0m 5.028   \u001b[0m | \u001b[0m 33.91   \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6519  \u001b[0m | \u001b[0m 8.338   \u001b[0m | \u001b[0m 39.27   \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6835  \u001b[0m | \u001b[0m 5.162   \u001b[0m | \u001b[0m 26.46   \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6456  \u001b[0m | \u001b[0m 7.209   \u001b[0m | \u001b[0m 44.73   \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6456  \u001b[0m | \u001b[0m 5.093   \u001b[0m | \u001b[0m 33.15   \u001b[0m |\n",
            "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.6962  \u001b[0m | \u001b[95m 6.976   \u001b[0m | \u001b[95m 34.62   \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6266  \u001b[0m | \u001b[0m 8.451   \u001b[0m | \u001b[0m 23.67   \u001b[0m |\n",
            "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.7025  \u001b[0m | \u001b[95m 8.02    \u001b[0m | \u001b[95m 24.55   \u001b[0m |\n",
            "| \u001b[95m 13      \u001b[0m | \u001b[95m 0.7342  \u001b[0m | \u001b[95m 8.964   \u001b[0m | \u001b[95m 46.52   \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6962  \u001b[0m | \u001b[0m 7.097   \u001b[0m | \u001b[0m 24.96   \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6772  \u001b[0m | \u001b[0m 5.575   \u001b[0m | \u001b[0m 25.95   \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6835  \u001b[0m | \u001b[0m 9.777   \u001b[0m | \u001b[0m 27.84   \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6646  \u001b[0m | \u001b[0m 9.068   \u001b[0m | \u001b[0m 44.07   \u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.6582  \u001b[0m | \u001b[0m 6.042   \u001b[0m | \u001b[0m 43.25   \u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7215  \u001b[0m | \u001b[0m 9.096   \u001b[0m | \u001b[0m 40.42   \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6456  \u001b[0m | \u001b[0m 7.51    \u001b[0m | \u001b[0m 40.16   \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6266  \u001b[0m | \u001b[0m 8.173   \u001b[0m | \u001b[0m 42.96   \u001b[0m |\n",
            "=================================================\n",
            "Best result: {'k_fold': 8.963766195062924, 'test_size': 46.51833273688793}; Accuracy = 0.7341772151898734.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest\n",
        "pbounds = {\n",
        "    'k_fold': (5, 10), \n",
        "    'test_size':(20,50),\n",
        "    # 'max_depth':(100,1000),\n",
        "    'n_estimators':(100,1000),\n",
        "    }\n",
        "optimizer_rf = BayesianOptimization(\n",
        "    f=randomForest,\n",
        "    pbounds=pbounds,\n",
        "    verbose=2, \n",
        "    random_state=42,\n",
        ")\n",
        "optimizer_rf.maximize(init_points = 0, n_iter = 20)\n",
        "print(\"Best result: {}; Accuracy = {}.\".format(optimizer_rf.max[\"params\"], optimizer_rf.max[\"target\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOOaebjjC3O8",
        "outputId": "e29f171a-0412-47b9-d7e0-12fe98e73f7c"
      },
      "execution_count": 457,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   |  k_fold   | n_esti... | test_size |\n",
            "-------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7048  \u001b[0m | \u001b[0m 6.873   \u001b[0m | \u001b[0m 955.6   \u001b[0m | \u001b[0m 41.96   \u001b[0m |\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.6857  \u001b[0m | \u001b[0m 9.857   \u001b[0m | \u001b[0m 669.2   \u001b[0m | \u001b[0m 49.58   \u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.6857  \u001b[0m | \u001b[0m 6.657   \u001b[0m | \u001b[0m 956.1   \u001b[0m | \u001b[0m 40.5    \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6857  \u001b[0m | \u001b[0m 6.626   \u001b[0m | \u001b[0m 531.2   \u001b[0m | \u001b[0m 24.28   \u001b[0m |\n",
            "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.7143  \u001b[0m | \u001b[95m 9.715   \u001b[0m | \u001b[95m 431.1   \u001b[0m | \u001b[95m 26.64   \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6762  \u001b[0m | \u001b[0m 9.47    \u001b[0m | \u001b[0m 875.4   \u001b[0m | \u001b[0m 32.4    \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6571  \u001b[0m | \u001b[0m 6.662   \u001b[0m | \u001b[0m 711.9   \u001b[0m | \u001b[0m 48.89   \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7143  \u001b[0m | \u001b[0m 5.472   \u001b[0m | \u001b[0m 821.1   \u001b[0m | \u001b[0m 37.87   \u001b[0m |\n",
            "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.7524  \u001b[0m | \u001b[95m 6.523   \u001b[0m | \u001b[95m 956.4   \u001b[0m | \u001b[95m 41.65   \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7429  \u001b[0m | \u001b[0m 5.835   \u001b[0m | \u001b[0m 821.0   \u001b[0m | \u001b[0m 37.48   \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6952  \u001b[0m | \u001b[0m 5.7     \u001b[0m | \u001b[0m 955.8   \u001b[0m | \u001b[0m 41.22   \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6667  \u001b[0m | \u001b[0m 6.541   \u001b[0m | \u001b[0m 875.0   \u001b[0m | \u001b[0m 22.82   \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7143  \u001b[0m | \u001b[0m 6.228   \u001b[0m | \u001b[0m 819.8   \u001b[0m | \u001b[0m 37.49   \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6952  \u001b[0m | \u001b[0m 6.341   \u001b[0m | \u001b[0m 329.8   \u001b[0m | \u001b[0m 35.13   \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7524  \u001b[0m | \u001b[0m 8.062   \u001b[0m | \u001b[0m 155.4   \u001b[0m | \u001b[0m 32.75   \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6667  \u001b[0m | \u001b[0m 6.027   \u001b[0m | \u001b[0m 821.1   \u001b[0m | \u001b[0m 36.47   \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7333  \u001b[0m | \u001b[0m 9.729   \u001b[0m | \u001b[0m 506.3   \u001b[0m | \u001b[0m 47.31   \u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7143  \u001b[0m | \u001b[0m 8.403   \u001b[0m | \u001b[0m 418.5   \u001b[0m | \u001b[0m 24.32   \u001b[0m |\n",
            "| \u001b[95m 19      \u001b[0m | \u001b[95m 0.7619  \u001b[0m | \u001b[95m 6.682   \u001b[0m | \u001b[95m 152.3   \u001b[0m | \u001b[95m 46.36   \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6762  \u001b[0m | \u001b[0m 7.799   \u001b[0m | \u001b[0m 154.8   \u001b[0m | \u001b[0m 32.6    \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7238  \u001b[0m | \u001b[0m 6.646   \u001b[0m | \u001b[0m 966.8   \u001b[0m | \u001b[0m 35.16   \u001b[0m |\n",
            "=============================================================\n",
            "Best result: {'k_fold': 6.681652761561051, 'n_estimators': 152.31473216757047, 'test_size': 46.35542729717372}; Accuracy = 0.7619047619047619.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DNN\n",
        "pbounds = {\n",
        "    'k_fold': (5, 10), \n",
        "    'test_size':(20,50),\n",
        "    'epochs': (10,50), \n",
        "    'learning_rate':(0.0001,0.01),\n",
        "    'batch_size': (10, 100), \n",
        "    'vect_dim':(8,128),\n",
        "    'neurons':(8,128),\n",
        "    'dropout':(0.2,0.8)\n",
        "    }\n",
        "optimizer_dnn = BayesianOptimization(\n",
        "    f=dnn,\n",
        "    pbounds=pbounds,\n",
        "    verbose=2, \n",
        "    random_state=42,\n",
        ")\n",
        "optimizer_dnn.maximize(init_points = 0, n_iter = 5)\n",
        "print(\"Best result: {}; Accuracy = {}.\".format(optimizer_dnn.max[\"params\"], optimizer_dnn.max[\"target\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsphAgqyDDKm",
        "outputId": "1f14819f-7021-4394-8640-d81e522f51c4"
      },
      "execution_count": 458,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   | batch_... |  dropout  |  epochs   |  k_fold   | learni... |  neurons  | test_size | vect_dim  |\n",
            "-------------------------------------------------------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9625  \u001b[0m | \u001b[0m 43.71   \u001b[0m | \u001b[0m 0.7704  \u001b[0m | \u001b[0m 39.28   \u001b[0m | \u001b[0m 7.993   \u001b[0m | \u001b[0m 0.001645\u001b[0m | \u001b[0m 26.72   \u001b[0m | \u001b[0m 21.74   \u001b[0m | \u001b[0m 111.9   \u001b[0m |\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.9806  \u001b[0m | \u001b[95m 44.25   \u001b[0m | \u001b[95m 0.7151  \u001b[0m | \u001b[95m 40.18   \u001b[0m | \u001b[95m 5.092   \u001b[0m | \u001b[95m 0.001748\u001b[0m | \u001b[95m 64.88   \u001b[0m | \u001b[95m 39.76   \u001b[0m | \u001b[95m 93.82   \u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.9318  \u001b[0m | \u001b[0m 43.88   \u001b[0m | \u001b[0m 0.6523  \u001b[0m | \u001b[0m 40.21   \u001b[0m | \u001b[0m 6.048   \u001b[0m | \u001b[0m 0.003825\u001b[0m | \u001b[0m 68.3    \u001b[0m | \u001b[0m 37.62   \u001b[0m | \u001b[0m 97.09   \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.9633  \u001b[0m | \u001b[0m 22.27   \u001b[0m | \u001b[0m 0.6042  \u001b[0m | \u001b[0m 30.45   \u001b[0m | \u001b[0m 5.131   \u001b[0m | \u001b[0m 0.000649\u001b[0m | \u001b[0m 37.76   \u001b[0m | \u001b[0m 49.14   \u001b[0m | \u001b[0m 102.8   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9337  \u001b[0m | \u001b[0m 59.33   \u001b[0m | \u001b[0m 0.7474  \u001b[0m | \u001b[0m 13.38   \u001b[0m | \u001b[0m 7.246   \u001b[0m | \u001b[0m 0.002067\u001b[0m | \u001b[0m 78.88   \u001b[0m | \u001b[0m 31.66   \u001b[0m | \u001b[0m 82.75   \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.9456  \u001b[0m | \u001b[0m 33.54   \u001b[0m | \u001b[0m 0.692   \u001b[0m | \u001b[0m 49.18   \u001b[0m | \u001b[0m 5.756   \u001b[0m | \u001b[0m 0.008449\u001b[0m | \u001b[0m 97.7    \u001b[0m | \u001b[0m 39.55   \u001b[0m | \u001b[0m 116.8   \u001b[0m |\n",
            "=========================================================================================================================\n",
            "Best result: {'batch_size': 44.24746494201208, 'dropout': 0.7150640196832985, 'epochs': 40.17707416790569, 'k_fold': 5.091830877870115, 'learning_rate': 0.001748330827456348, 'neurons': 64.8841416741131, 'test_size': 39.7604079547944, 'vect_dim': 93.81511395152666}; Accuracy = 0.9805593348450492.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Numerical_Hyperparameter_Optimization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO3Xmtlk2glgtklZ2wMFEgO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}